{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this file:\n",
    "- Using data of 1702 frequent authors (having 3 or more than 3 papers in the data sets)\n",
    "- Model: NB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import getcwd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "import os\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from sklearn import  naive_bayes, pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_path():\n",
    "    abspath = getcwd()\n",
    "    dname = os.path.dirname(abspath)\n",
    "    os.chdir(dname)\n",
    "set_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5984, 2), (500, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_pickle('data/processed/train_3pp_df.pkl')\n",
    "df_val = pd.read_pickle('data/processed/val_3pp_df.pkl')\n",
    "df_train.shape, df_val.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words:\n",
    "\n",
    "Get x common words out of each author's corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author 4261 has maximum unique words: 479\n",
      "author 849 has maximum unique words: 29\n",
      "average number of unique words per author is 152.2855464159812\n"
     ]
    }
   ],
   "source": [
    "# checking number of unique words in each author's corpus \n",
    "def get_author_unique_corpus(df):\n",
    "   listauthor = df['authId_enc'].unique()\n",
    "   corpus_auth = {}\n",
    "   for au in listauthor:\n",
    "      totalword = []\n",
    "      auth_content = df.loc[df['authId_enc'] == au, 'content']\n",
    "      for art in auth_content:\n",
    "         wordlist = art.split()\n",
    "         totalword += wordlist\n",
    "      corpus_auth[au] = list(set(totalword))\n",
    "   return corpus_auth\n",
    "corpus_by_author = get_author_unique_corpus(df_train)\n",
    "\n",
    "num_corpus = {k:len(v) for k, v in corpus_by_author.items() }\n",
    "max_uniq_w = max(num_corpus, key = num_corpus.get)\n",
    "print(f'author {max_uniq_w} has maximum unique words: {num_corpus[max_uniq_w]}' )\n",
    "min_uniq_w = min(num_corpus, key = num_corpus.get)\n",
    "print(f'author {min_uniq_w} has maximum unique words: {num_corpus[min_uniq_w]}' )\n",
    "print(f'average number of unique words per author is {np.mean(list(num_corpus.values()))}' )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering and selection with Tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(max_features=3000, )\n",
    "corpus = df_train['content']\n",
    "vectorizer.fit(corpus)\n",
    "Xtrain = vectorizer.transform(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection by chi2\n",
    "Xnames = vectorizer.get_feature_names_out() ## original full corpus\n",
    "p_value_limit = 0.95\n",
    "df_features = pd.DataFrame()\n",
    "for author in np.unique(df_train['authId_enc']):\n",
    "   X= Xtrain.toarray()\n",
    "   Y = df_train['authId_enc'] ==author\n",
    "   chi, p = chi2(X, Y)\n",
    "   df_features = pd.concat([df_features, \n",
    "   pd.DataFrame({'feature': Xnames, 'score' : 1-p, 'authId_enc': author})])\n",
    "\n",
    "   df_features = df_features[df_features['score'] > p_value_limit]\n",
    "df_features = df_features.sort_values(['authId_enc', 'score'],\n",
    "                                          ascending = [True, False])\n",
    "Xnames = df_features['feature'].unique().tolist() # selected words for new corpus from feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author 904 has the least unique chosen words 9 \n"
     ]
    }
   ],
   "source": [
    "count_uniq_w_author = Counter(df_features[\"authId_enc\"])\n",
    "min_auth = min(count_uniq_w_author, key = count_uniq_w_author.get)\n",
    "print(f'author {min_auth} has the least unique chosen words {count_uniq_w_author[min_auth]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0:\n",
      "  . selected features: 26\n",
      "  . top features: instanti,situat,distanc,googl,anaphor,parametr,bridg,violat,largest,pronomin\n",
      " \n",
      "# 1:\n",
      "  . selected features: 21\n",
      "  . top features: monitor,environ,familiar,rise,finnish,morpholog,thank,rich,modif,inflect\n",
      " \n",
      "# 3:\n",
      "  . selected features: 27\n",
      "  . top features: cohes,electron,themat,thesaurus,criterion,index,late,dictionari,colloc,brought\n",
      " \n",
      "# 5:\n",
      "  . selected features: 41\n",
      "  . top features: agenda,selfreport,discoveri,diagnosi,ptsd,impract,clpsych,englishfrench,semiautomat,quot\n",
      " \n",
      "# 9:\n",
      "  . selected features: 31\n",
      "  . top features: framesemant,meme,fake,timelin,texton,first,lowrank,probabilist,arc,reinforc\n",
      " \n",
      "# 11:\n",
      "  . selected features: 32\n",
      "  . top features: explain,spectrum,expos,arguabl,proofofconcept,burden,countbas,diagnos,end,expens\n",
      " \n",
      "# 12:\n",
      "  . selected features: 34\n",
      "  . top features: contextfre,tabular,deduct,bilex,grammar,latentvari,prefix,algorithm,pars,termin\n",
      " \n",
      "# 14:\n",
      "  . selected features: 29\n",
      "  . top features: download,nonparallel,mix,queri,secondari,newspap,electron,nearest,materi,fortun\n",
      " \n",
      "# 15:\n",
      "  . selected features: 39\n",
      "  . top features: credibl,cqa,subtask,tune,prolifer,noun,unavail,quest,answer,compound\n",
      " \n",
      "# 16:\n",
      "  . selected features: 20\n",
      "  . top features: collabor,conflict,holder,negoti,initi,warrant,cycl,belief,inevit,cue\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# PRINT out selected feature by author\n",
    "for author in np.unique(df_train['authId_enc'])[:10]:\n",
    "   print(\"# {}:\".format(author))\n",
    "   print(\"  . selected features:\",\n",
    "         len(df_features[df_features[\"authId_enc\"]==author]))\n",
    "   print(\"  . top features:\", \",\".join(\n",
    "df_features[df_features[\"authId_enc\"]==author][\"feature\"].values[:10]))\n",
    "   print(\" \")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2964"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit vectorizer in the new corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=Xnames)\n",
    "vectorizer.fit(corpus)\n",
    "Xtrain_new = vectorizer.transform(corpus)\n",
    "ytrain = df_train['authId_enc'].values\n",
    "yval= df_val['authId_enc'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierNB = naive_bayes.MultinomialNB()\n",
    "## pipeline\n",
    "modelNB = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           (\"classifier\", classifierNB)])\n",
    "## train classifier\n",
    "modelNB[\"classifier\"].fit(Xtrain_new, ytrain)\n",
    "## test\n",
    "Xval = df_val['content'].values\n",
    "predicted = modelNB.predict(Xval)\n",
    "predicted_prob = modelNB.predict_proba(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(yval, predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune MultiNomial NB model with Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = df_train['content']\n",
    "ytrain = df_train['authId_enc'].values\n",
    "vectorizer = TfidfVectorizer()\n",
    "classifierNB = naive_bayes.MultinomialNB()\n",
    "modelNB = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           (\"classifier\", classifierNB)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                                       ('classifier', MultinomialNB())]),\n",
       "             param_grid={'classifier__alpha': array([0.5, 1. , 1.5]),\n",
       "                         'classifier__fit_prior': [True, False],\n",
       "                         'vectorizer__binary': [True, False],\n",
       "                         'vectorizer__max_df': [0.1, 0.5, 1],\n",
       "                         'vectorizer__max_features': [1000, 1500, 2000, 2500,\n",
       "                                                      3000],\n",
       "                         'vectorizer__norm': [None, 'l1', 'l2']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_params = {\n",
    "  'classifier__alpha': np.linspace(0.5, 1.5, 3),\n",
    "  'classifier__fit_prior': [True, False],\n",
    "  'vectorizer__max_df': [0.1, 0.5, 1],\n",
    "  'vectorizer__binary': [True, False],\n",
    "  'vectorizer__norm': [None, 'l1', 'l2'], \n",
    "  'vectorizer__max_features': [1000, 1500, 2000, 2500, 3000],\n",
    "}\n",
    "clf = GridSearchCV(modelNB, grid_params, cv = 2, scoring='accuracy')\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'classifier__alpha': 0.5,\n",
       "  'classifier__fit_prior': False,\n",
       "  'vectorizer__binary': False,\n",
       "  'vectorizer__max_df': 0.5,\n",
       "  'vectorizer__max_features': 3000,\n",
       "  'vectorizer__norm': None},\n",
       " 0.1602606951871658)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_, clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.214"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval = df_val['content'].values\n",
    "predicted = clf.predict(Xval)\n",
    "accuracy = accuracy_score(yval, predicted)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter\n",
      " {'classifier__alpha': 0.5, 'classifier__fit_prior': False, 'vectorizer__binary': False, 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 2500, 'vectorizer__norm': None} \n",
      "Best score\n",
      " 0.15925802139037432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.208"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trail with max_feature = 2500\n",
    "Xtrain = df_train['content']\n",
    "ytrain = df_train['authId_enc'].values\n",
    "vectorizer = TfidfVectorizer()\n",
    "classifierNB = naive_bayes.MultinomialNB()\n",
    "modelNB = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           (\"classifier\", classifierNB)])\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_params = {\n",
    "  'classifier__alpha': np.linspace(0.5, 1.5, 3),\n",
    "  'classifier__fit_prior': [True, False],\n",
    "  'vectorizer__max_df': [0.1, 0.5, 1],\n",
    "  'vectorizer__binary': [True, False],\n",
    "  'vectorizer__norm': [None, 'l1', 'l2'], \n",
    "  'vectorizer__max_features': [1000, 1500, 2000, 2500,]\n",
    "}\n",
    "clf = GridSearchCV(modelNB, grid_params, cv = 2, scoring='accuracy')\n",
    "clf.fit(Xtrain, ytrain)\n",
    "print('Best parameter\\n', clf.best_params_,'\\nBest score\\n', clf.best_score_)\n",
    "Xval = df_val['content'].values\n",
    "predicted = clf.predict(Xval)\n",
    "accuracy = accuracy_score(yval, predicted)\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                                       ('classifier', MultinomialNB())]),\n",
       "             param_grid={'classifier__alpha': array([0.5, 1. , 1.5]),\n",
       "                         'classifier__fit_prior': [True, False],\n",
       "                         'vectorizer__binary': [True, False],\n",
       "                         'vectorizer__max_df': [0.1, 0.5, 1],\n",
       "                         'vectorizer__max_features': [2500, 3000, 3500],\n",
       "                         'vectorizer__norm': [None, 'l1', 'l2']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trail with max_feature = 3500\n",
    "Xtrain = df_train['content']\n",
    "ytrain = df_train['authId_enc'].values\n",
    "vectorizer = TfidfVectorizer()\n",
    "classifierNB = naive_bayes.MultinomialNB()\n",
    "modelNB = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           (\"classifier\", classifierNB)])\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_params = {\n",
    "  'classifier__alpha': np.linspace(0.5, 1.5, 3),\n",
    "  'classifier__fit_prior': [True, False],\n",
    "  'vectorizer__max_df': [0.1, 0.5, 1],\n",
    "  'vectorizer__binary': [True, False],\n",
    "  'vectorizer__norm': [None, 'l1', 'l2'], \n",
    "  'vectorizer__max_features': [2500,3000, 3500]\n",
    "}\n",
    "clf = GridSearchCV(modelNB, grid_params, cv = 2, scoring='accuracy')\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier__alpha': 0.5,\n",
       " 'classifier__fit_prior': False,\n",
       " 'vectorizer__binary': False,\n",
       " 'vectorizer__max_df': 0.5,\n",
       " 'vectorizer__max_features': 3500,\n",
       " 'vectorizer__norm': None}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best parameter')\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16059491978609625"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best score')\n",
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.202"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Xval = df_val['content'].values\n",
    "predicted = clf.predict(Xval)\n",
    "accuracy = accuracy_score(yval, predicted)\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### chosen model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6484, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = pd.concat([df_train, df_val], ignore_index=True, axis=0)\n",
    "df_combined.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(max_df=0.5, max_features=3000, norm=None)),\n",
       "                ('classifier', MultinomialNB(alpha=0.5, fit_prior=False))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xcombined = df_combined['content']\n",
    "ycombined = df_combined['authId_enc'].values\n",
    "vectorizer = TfidfVectorizer(max_df=0.5,\n",
    "                              max_features=3000,\n",
    "                              norm=None)\n",
    "classifierNB = naive_bayes.MultinomialNB(fit_prior=False,alpha=0.5)\n",
    "modelNB_final= pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           (\"classifier\", classifierNB)])\n",
    "\n",
    "modelNB_final.fit(Xcombined, ycombined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_pickle('data/processed/test_clean_df.pkl')\n",
    "\n",
    "# get lable encoder of author\n",
    "with open('code/authorIdlabel_3papers.pkl', 'rb') as f:\n",
    "   authorId_encoder = pickle.load(file = f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6531"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = df_test['content'].values\n",
    "predicted = modelNB_final.predict(Xtest)\n",
    "predictauthorId = authorId_encoder.inverse_transform(predicted)\n",
    "len(predictauthorId)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1821892,   33464127, 1390037280, ...,    2814303,    1763912,\n",
       "         40895369], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictauthorId"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([  33524946,   33464127, 1390037280, ...,    2814303,    1763912,\n",
    "         67284811], dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>authorId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86e1aaa0c47659e08a896e9889384eb1e5401e6a</td>\n",
       "      <td>1821892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8d3076c38f56df22052567f4783c670d8e860f09</td>\n",
       "      <td>33464127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7c400ee676d427eeda1aad5c1c54c316f0b9773d</td>\n",
       "      <td>1390037280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185e7d2a761594451b02ace240356dadad2aef78</td>\n",
       "      <td>3017695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e4363d077a890c8d5c5e66b82fe69a1bbbdd5c80</td>\n",
       "      <td>49889487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    paperId    authorId\n",
       "0  86e1aaa0c47659e08a896e9889384eb1e5401e6a     1821892\n",
       "1  8d3076c38f56df22052567f4783c670d8e860f09    33464127\n",
       "2  7c400ee676d427eeda1aad5c1c54c316f0b9773d  1390037280\n",
       "3  185e7d2a761594451b02ace240356dadad2aef78     3017695\n",
       "4  e4363d077a890c8d5c5e66b82fe69a1bbbdd5c80    49889487"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictauthorId = list(map(str, predictauthorId))\n",
    "df_test['authorId']= predictauthorId\n",
    "df_test = df_test[['paperId', 'authorId']].copy()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_json('data/processed/predicted.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.214"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing final model \n",
    "Xtrain, Xval = df_train['content'].values, df_val['content'].values\n",
    "ytrain, yval = df_train['authId_enc'].values, df_val['authId_enc'].values\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5,\n",
    "                              max_features=3000,\n",
    "                              norm=None)\n",
    "classifierNB = naive_bayes.MultinomialNB(fit_prior=False,alpha=0.5)\n",
    "modelNB_final= pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           (\"classifier\", classifierNB)])\n",
    "\n",
    "modelNB_final.fit(Xtrain, ytrain)\n",
    "\n",
    "\n",
    "predicted = modelNB_final.predict(Xval)\n",
    "accuracy = accuracy_score(yval, predicted)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bbd7653c429d3d2de6e8bc2b15128056d2671a20efb53a45ef350876c14518f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
