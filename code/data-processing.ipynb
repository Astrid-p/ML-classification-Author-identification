{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy\n",
    "from os import getcwd\n",
    "from os.path import join\n",
    "read_file= open(join(getcwd()[:-len('code')], 'data','train.json'))\n",
    "read_test= open(join(getcwd()[:-len('code')], 'data','test.json'))\n",
    "train_file= json.load(read_file)\n",
    "test_file= json.load(read_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12129"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paperId': '0b341b6938308a6d5f47edf490f6e46eae3835fa',\n",
       " 'title': 'Detecting linguistic idiosyncratic interests in autism using distributional semantic models',\n",
       " 'authorId': '3188285',\n",
       " 'authorName': 'Masoud Rouhizadeh',\n",
       " 'abstract': 'Children with autism spectrum disorder often exhibit idiosyncratic patterns of behaviors and interests. In this paper, we focus on measuring the presence of idiosyncratic interests at the linguistic level in children with autism using distributional semantic models. We model the semantic space of children’s narratives by calculating pairwise word overlap, and we compare the overlap found within and across diagnostic groups. We find that the words used by children with typical development tend to be used by other children with typical development, while the words used by children with autism overlap less with those used by children with typical development and even less with those used by other children with autism. These findings suggest that children with autism are veering not only away from the topic of the target narrative but also in idiosyncratic semantic directions potentially defined by their individual topics of interest.',\n",
       " 'year': 2014,\n",
       " 'venue': 'CLPsych@ACL'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authorIf(data, key1, key2):\n",
    "    dicmap ={}\n",
    "    for i in data:         \n",
    "        dicmap[i[key1]] = i[key2]\n",
    "    return dicmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625\n",
      "5511\n"
     ]
    }
   ],
   "source": [
    "test1 = authorIf(train_file, 'authorId', 'authorName')\n",
    "print(len(test1))\n",
    "test2 = authorIf(train_file, 'authorName','authorId' )\n",
    "print(len(test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data's dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# word use by authorID\n",
    "def getwordlist(article):\n",
    "    wholetext = article['title'] + ' ' + article['abstract']\n",
    "    wholetext = wholetext.lower()\n",
    "    newtext = ''\n",
    "    for l in wholetext:\n",
    "        if l in '.,_:;/)(?”“-':\n",
    "            newtext += ' '\n",
    "        else:\n",
    "            newtext += l\n",
    "    return newtext.split()\n",
    "\n",
    "def getwordcount(article):\n",
    "    return dict(Counter(getwordlist(article)))\n",
    "\n",
    "def merging(dic1,dic2):\n",
    "    mergeddic = set(dic1) | set(dic2)\n",
    "    return {key: dic1.get(key, 0) + dic2.get(key, 0) for key in mergeddic}\n",
    "\n",
    "def getdictionary(data):\n",
    "    finaldic = {}\n",
    "    for a in data:\n",
    "        instancedic = getwordcount(a)\n",
    "        finaldic = merging(finaldic, instancedic)\n",
    "    return finaldic\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detecting': 1,\n",
       " 'linguistic': 2,\n",
       " 'idiosyncratic': 4,\n",
       " 'interests': 3,\n",
       " 'in': 4,\n",
       " 'autism': 6,\n",
       " 'using': 2,\n",
       " 'distributional': 2,\n",
       " 'semantic': 4,\n",
       " 'models': 2,\n",
       " 'children': 8,\n",
       " 'with': 10,\n",
       " 'spectrum': 1,\n",
       " 'disorder': 1,\n",
       " 'often': 1,\n",
       " 'exhibit': 1,\n",
       " 'patterns': 1,\n",
       " 'of': 5,\n",
       " 'behaviors': 1,\n",
       " 'and': 4,\n",
       " 'this': 1,\n",
       " 'paper': 1,\n",
       " 'we': 4,\n",
       " 'focus': 1,\n",
       " 'on': 1,\n",
       " 'measuring': 1,\n",
       " 'the': 8,\n",
       " 'presence': 1,\n",
       " 'at': 1,\n",
       " 'level': 1,\n",
       " 'model': 1,\n",
       " 'space': 1,\n",
       " 'children’s': 1,\n",
       " 'narratives': 1,\n",
       " 'by': 7,\n",
       " 'calculating': 1,\n",
       " 'pairwise': 1,\n",
       " 'word': 1,\n",
       " 'overlap': 3,\n",
       " 'compare': 1,\n",
       " 'found': 1,\n",
       " 'within': 1,\n",
       " 'across': 1,\n",
       " 'diagnostic': 1,\n",
       " 'groups': 1,\n",
       " 'find': 1,\n",
       " 'that': 2,\n",
       " 'words': 2,\n",
       " 'used': 5,\n",
       " 'typical': 3,\n",
       " 'development': 3,\n",
       " 'tend': 1,\n",
       " 'to': 1,\n",
       " 'be': 1,\n",
       " 'other': 2,\n",
       " 'while': 1,\n",
       " 'less': 2,\n",
       " 'those': 2,\n",
       " 'even': 1,\n",
       " 'these': 1,\n",
       " 'findings': 1,\n",
       " 'suggest': 1,\n",
       " 'are': 1,\n",
       " 'veering': 1,\n",
       " 'not': 1,\n",
       " 'only': 1,\n",
       " 'away': 1,\n",
       " 'from': 1,\n",
       " 'topic': 1,\n",
       " 'target': 1,\n",
       " 'narrative': 1,\n",
       " 'but': 1,\n",
       " 'also': 1,\n",
       " 'directions': 1,\n",
       " 'potentially': 1,\n",
       " 'defined': 1,\n",
       " 'their': 1,\n",
       " 'individual': 1,\n",
       " 'topics': 1,\n",
       " 'interest': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getwordcount(train_file[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 79461,\n",
       " 'of': 54424,\n",
       " 'and': 46255,\n",
       " 'a': 42031,\n",
       " 'to': 41086,\n",
       " 'in': 34455,\n",
       " 'we': 28270,\n",
       " 'for': 25222,\n",
       " 'on': 19558,\n",
       " 'that': 19117,\n",
       " 'is': 15779,\n",
       " 'this': 14115,\n",
       " 'with': 13662,\n",
       " 'our': 10835,\n",
       " 'model': 10220,\n",
       " 'as': 10203,\n",
       " 'language': 9472,\n",
       " 'are': 9064,\n",
       " 'from': 9010,\n",
       " 'by': 8961,\n",
       " 'models': 8879,\n",
       " 'task': 8669,\n",
       " 'an': 8419,\n",
       " 'based': 7670,\n",
       " 'data': 7111,\n",
       " 'which': 6755,\n",
       " 'can': 5808,\n",
       " 'learning': 5556,\n",
       " 'text': 5550,\n",
       " 'word': 5487,\n",
       " 'paper': 5375,\n",
       " 'be': 5204,\n",
       " 'using': 5163,\n",
       " 'translation': 5011,\n",
       " 'neural': 4935,\n",
       " 'show': 4925,\n",
       " 'system': 4677,\n",
       " 'results': 4636,\n",
       " 'training': 4560,\n",
       " 'it': 4436,\n",
       " 'approach': 4397,\n",
       " 'performance': 4363,\n",
       " 'information': 4254,\n",
       " 'tasks': 3964,\n",
       " 'two': 3934,\n",
       " 'or': 3925,\n",
       " 'propose': 3745,\n",
       " 'semantic': 3722,\n",
       " 'such': 3680,\n",
       " 'these': 3662,\n",
       " 'at': 3575,\n",
       " 'knowledge': 3489,\n",
       " 'method': 3488,\n",
       " 'state': 3488,\n",
       " 'have': 3478,\n",
       " 'not': 3352,\n",
       " 'different': 3336,\n",
       " 'machine': 3274,\n",
       " 'systems': 3219,\n",
       " 'methods': 3171,\n",
       " 'work': 3134,\n",
       " 'new': 3115,\n",
       " 'languages': 3109,\n",
       " 'more': 3089,\n",
       " 'domain': 3082,\n",
       " 'also': 3068,\n",
       " 'has': 3025,\n",
       " 'between': 2987,\n",
       " 'sentence': 2968,\n",
       " 'present': 2944,\n",
       " 'both': 2929,\n",
       " 'art': 2902,\n",
       " 'their': 2897,\n",
       " 'use': 2887,\n",
       " 'english': 2883,\n",
       " 'dataset': 2838,\n",
       " 'evaluation': 2771,\n",
       " 'features': 2739,\n",
       " 'natural': 2660,\n",
       " 'human': 2657,\n",
       " 'over': 2646,\n",
       " 'generation': 2626,\n",
       " 'used': 2599,\n",
       " 'analysis': 2594,\n",
       " 'words': 2566,\n",
       " 'level': 2539,\n",
       " 'corpus': 2507,\n",
       " 'datasets': 2500,\n",
       " 'trained': 2498,\n",
       " 'into': 2496,\n",
       " 'representations': 2495,\n",
       " 'large': 2441,\n",
       " 'experiments': 2422,\n",
       " 'parsing': 2373,\n",
       " 'context': 2332,\n",
       " 'embeddings': 2248,\n",
       " 'however': 2231,\n",
       " 'classification': 2205,\n",
       " 'but': 2199,\n",
       " 'multi': 2148,\n",
       " 'proposed': 2144,\n",
       " 'first': 2139,\n",
       " 'question': 2127,\n",
       " 'one': 2101,\n",
       " 'been': 2089,\n",
       " 'than': 2088,\n",
       " 'well': 2052,\n",
       " 'e': 2049,\n",
       " 'how': 2002,\n",
       " 'set': 2002,\n",
       " 'while': 1988,\n",
       " 'novel': 1980,\n",
       " 'only': 1959,\n",
       " 'each': 1958,\n",
       " 'when': 1954,\n",
       " 'other': 1930,\n",
       " 'attention': 1899,\n",
       " 'problem': 1895,\n",
       " 'nlp': 1865,\n",
       " 'existing': 1849,\n",
       " 'framework': 1840,\n",
       " 'sentences': 1839,\n",
       " 'cross': 1834,\n",
       " 'approaches': 1832,\n",
       " 'all': 1831,\n",
       " 'network': 1795,\n",
       " 'pre': 1774,\n",
       " 'sequence': 1747,\n",
       " 'representation': 1744,\n",
       " 'quality': 1740,\n",
       " 'its': 1731,\n",
       " 'entity': 1717,\n",
       " '1': 1696,\n",
       " 'sentiment': 1687,\n",
       " 'linguistic': 1676,\n",
       " 'dialogue': 1666,\n",
       " 'research': 1657,\n",
       " 'target': 1645,\n",
       " 'extraction': 1643,\n",
       " 'detection': 1639,\n",
       " 'they': 1606,\n",
       " 'better': 1604,\n",
       " 'study': 1590,\n",
       " 'most': 1588,\n",
       " 'shared': 1579,\n",
       " 'source': 1574,\n",
       " 'i': 1570,\n",
       " 'previous': 1563,\n",
       " 'demonstrate': 1562,\n",
       " 'time': 1559,\n",
       " 'automatic': 1559,\n",
       " 'accuracy': 1556,\n",
       " 'document': 1545,\n",
       " 'multiple': 1522,\n",
       " 'speech': 1511,\n",
       " 'processing': 1510,\n",
       " 'syntactic': 1504,\n",
       " 'dependency': 1491,\n",
       " 'graph': 1481,\n",
       " 'lexical': 1478,\n",
       " 'end': 1475,\n",
       " 'best': 1458,\n",
       " 'three': 1457,\n",
       " 'input': 1454,\n",
       " 'specific': 1447,\n",
       " 'then': 1445,\n",
       " 'supervised': 1441,\n",
       " 'structure': 1438,\n",
       " 'where': 1425,\n",
       " 'several': 1421,\n",
       " 'multilingual': 1404,\n",
       " 'available': 1404,\n",
       " 'improve': 1401,\n",
       " 'given': 1386,\n",
       " 'across': 1386,\n",
       " '2': 1385,\n",
       " 'introduce': 1369,\n",
       " 'discourse': 1361,\n",
       " 'many': 1361,\n",
       " 'relations': 1356,\n",
       " 'non': 1334,\n",
       " 'corpora': 1315,\n",
       " 'further': 1313,\n",
       " 'high': 1300,\n",
       " 'test': 1299,\n",
       " 'modeling': 1298,\n",
       " 'similarity': 1270,\n",
       " 'simple': 1262,\n",
       " 'outperforms': 1261,\n",
       " 'recent': 1259,\n",
       " 'annotation': 1254,\n",
       " 'understanding': 1251,\n",
       " 'questions': 1251,\n",
       " 'user': 1245,\n",
       " 'fine': 1240,\n",
       " 'relation': 1235,\n",
       " 'networks': 1235,\n",
       " 'find': 1233,\n",
       " 'prediction': 1231,\n",
       " 'them': 1228,\n",
       " 'bert': 1228,\n",
       " 'unsupervised': 1221,\n",
       " 'resource': 1218,\n",
       " 'pairs': 1189,\n",
       " 'about': 1179,\n",
       " 'order': 1175,\n",
       " 'evaluate': 1167,\n",
       " 'some': 1165,\n",
       " 'g': 1151,\n",
       " 'through': 1148,\n",
       " 'deep': 1146,\n",
       " 'summarization': 1142,\n",
       " 'without': 1138,\n",
       " 'provide': 1136,\n",
       " 'social': 1130,\n",
       " 'low': 1126,\n",
       " 'baseline': 1125,\n",
       " 'annotated': 1121,\n",
       " 'algorithm': 1118,\n",
       " 'automatically': 1117,\n",
       " 'standard': 1116,\n",
       " 'learn': 1112,\n",
       " 'event': 1109,\n",
       " 'texts': 1109,\n",
       " 'semeval': 1104,\n",
       " 'answering': 1103,\n",
       " 'transfer': 1091,\n",
       " 'score': 1082,\n",
       " 'inference': 1081,\n",
       " 'various': 1071,\n",
       " 'achieves': 1067,\n",
       " 'effective': 1067,\n",
       " 'experimental': 1060,\n",
       " 'lingual': 1050,\n",
       " 'generated': 1045,\n",
       " 'often': 1043,\n",
       " 'scale': 1041,\n",
       " 'embedding': 1033,\n",
       " 'types': 1019,\n",
       " 'significantly': 1013,\n",
       " 'techniques': 1012,\n",
       " 'generate': 1004,\n",
       " 'transformer': 1003,\n",
       " 'process': 1001,\n",
       " 'via': 1000,\n",
       " 'important': 998,\n",
       " 'answer': 987,\n",
       " 'chinese': 987,\n",
       " 'feature': 983,\n",
       " 'same': 976,\n",
       " 'do': 975,\n",
       " 'open': 974,\n",
       " 'number': 971,\n",
       " 'news': 958,\n",
       " 'including': 956,\n",
       " 'out': 954,\n",
       " 'recognition': 953,\n",
       " 'entities': 951,\n",
       " 'al': 945,\n",
       " 'reasoning': 942,\n",
       " 'there': 938,\n",
       " '0': 924,\n",
       " 'code': 919,\n",
       " 'parser': 917,\n",
       " 'terms': 916,\n",
       " 'single': 914,\n",
       " 'parallel': 910,\n",
       " 'content': 909,\n",
       " 'describe': 902,\n",
       " 'topic': 897,\n",
       " 'achieve': 897,\n",
       " 'was': 892,\n",
       " 'et': 889,\n",
       " 'complex': 887,\n",
       " 'space': 883,\n",
       " 'metrics': 881,\n",
       " 'domains': 880,\n",
       " 'statistical': 867,\n",
       " 'benchmark': 865,\n",
       " 'related': 862,\n",
       " 'may': 858,\n",
       " 'architecture': 857,\n",
       " 'strong': 852,\n",
       " 'meaning': 848,\n",
       " 'train': 846,\n",
       " 'compared': 845,\n",
       " 'baselines': 844,\n",
       " 'tree': 843,\n",
       " 'current': 843,\n",
       " 'any': 836,\n",
       " 'improvements': 833,\n",
       " 'perform': 832,\n",
       " 'significant': 831,\n",
       " 'documents': 822,\n",
       " 'search': 819,\n",
       " 'identification': 817,\n",
       " 'up': 816,\n",
       " 'even': 814,\n",
       " 'computational': 814,\n",
       " 'will': 813,\n",
       " 'nmt': 809,\n",
       " 'applications': 809,\n",
       " 'general': 806,\n",
       " 'part': 805,\n",
       " 'long': 803,\n",
       " 'error': 796,\n",
       " 'media': 792,\n",
       " 'output': 788,\n",
       " 'investigate': 785,\n",
       " 'f1': 785,\n",
       " 'second': 783,\n",
       " 'improves': 782,\n",
       " 'address': 780,\n",
       " 'describes': 778,\n",
       " 'named': 777,\n",
       " 'sense': 775,\n",
       " 'resources': 772,\n",
       " 'make': 768,\n",
       " 'phrase': 768,\n",
       " 'structures': 767,\n",
       " 'real': 764,\n",
       " 'challenging': 756,\n",
       " 'retrieval': 755,\n",
       " 'shot': 753,\n",
       " 'focus': 751,\n",
       " 'textual': 746,\n",
       " 'identify': 746,\n",
       " 'explore': 744,\n",
       " 'scores': 744,\n",
       " 'self': 743,\n",
       " 'what': 736,\n",
       " 'challenge': 734,\n",
       " 'semantics': 732,\n",
       " 'encoder': 729,\n",
       " 'vector': 728,\n",
       " '3': 727,\n",
       " 'uses': 725,\n",
       " 'very': 721,\n",
       " 'generating': 712,\n",
       " 'morphological': 708,\n",
       " 'improvement': 708,\n",
       " 'labels': 707,\n",
       " 'few': 706,\n",
       " 'alignment': 705,\n",
       " 'examples': 704,\n",
       " 'capture': 702,\n",
       " 'way': 696,\n",
       " 'presents': 691,\n",
       " 'small': 691,\n",
       " 'latent': 691,\n",
       " 'form': 690,\n",
       " 'no': 685,\n",
       " 'online': 685,\n",
       " 'grammar': 685,\n",
       " 'evidence': 684,\n",
       " 'effectiveness': 682,\n",
       " 'users': 680,\n",
       " 'selection': 679,\n",
       " 'like': 679,\n",
       " 'role': 670,\n",
       " 'shown': 669,\n",
       " 'similar': 668,\n",
       " 'label': 668,\n",
       " 'achieved': 666,\n",
       " 'n': 660,\n",
       " 'studies': 658,\n",
       " 'tuning': 658,\n",
       " 'learned': 656,\n",
       " 'world': 656,\n",
       " 'character': 656,\n",
       " 'within': 655,\n",
       " 'sets': 655,\n",
       " 'were': 655,\n",
       " 'structured': 653,\n",
       " 'does': 653,\n",
       " 'particular': 652,\n",
       " 'qa': 652,\n",
       " 'events': 649,\n",
       " 'common': 648,\n",
       " 'case': 647,\n",
       " 'due': 646,\n",
       " 'among': 645,\n",
       " 'so': 642,\n",
       " 'efficient': 642,\n",
       " 'addition': 642,\n",
       " 'whether': 641,\n",
       " 'limited': 638,\n",
       " 'decoder': 637,\n",
       " 'additional': 636,\n",
       " 'annotations': 635,\n",
       " 'bleu': 634,\n",
       " 'relevant': 634,\n",
       " 'joint': 633,\n",
       " 'type': 632,\n",
       " 'towards': 632,\n",
       " 'during': 629,\n",
       " 'reading': 629,\n",
       " 'predict': 628,\n",
       " 'bias': 627,\n",
       " 'coreference': 626,\n",
       " 'thus': 621,\n",
       " 'german': 619,\n",
       " 'shows': 618,\n",
       " 'improving': 617,\n",
       " 'dialog': 616,\n",
       " 'compare': 614,\n",
       " 'tagging': 613,\n",
       " 'algorithms': 612,\n",
       " 'applied': 611,\n",
       " 'provides': 609,\n",
       " 'possible': 607,\n",
       " 'aspect': 603,\n",
       " 'visual': 601,\n",
       " 'argument': 601,\n",
       " 'under': 599,\n",
       " 'able': 598,\n",
       " 'adversarial': 597,\n",
       " 'problems': 596,\n",
       " 'temporal': 596,\n",
       " 'labeled': 590,\n",
       " 'prior': 587,\n",
       " 'finally': 584,\n",
       " 'resolution': 583,\n",
       " 'patterns': 582,\n",
       " 'recently': 581,\n",
       " 'monolingual': 577,\n",
       " 'mt': 576,\n",
       " 'rules': 575,\n",
       " 'labeling': 574,\n",
       " 'support': 574,\n",
       " 'identifying': 573,\n",
       " 'those': 571,\n",
       " 'allows': 571,\n",
       " 'memory': 569,\n",
       " 'classifier': 567,\n",
       " 'need': 566,\n",
       " 'help': 564,\n",
       " 'dependencies': 563,\n",
       " 'supervision': 563,\n",
       " 'rich': 562,\n",
       " 'specifically': 562,\n",
       " 'twitter': 561,\n",
       " 'contextual': 561,\n",
       " 'setting': 557,\n",
       " 'segmentation': 557,\n",
       " 'ranking': 552,\n",
       " 'future': 552,\n",
       " 'ability': 551,\n",
       " 'useful': 551,\n",
       " 'image': 550,\n",
       " 'step': 549,\n",
       " 'aware': 548,\n",
       " 'decoding': 548,\n",
       " 'lexicon': 546,\n",
       " 'pretrained': 546,\n",
       " 'competitive': 546,\n",
       " 'zero': 543,\n",
       " 'design': 543,\n",
       " 'much': 542,\n",
       " 'empirical': 541,\n",
       " 'improved': 540,\n",
       " 'short': 537,\n",
       " 'challenges': 536,\n",
       " 'still': 536,\n",
       " 'if': 535,\n",
       " 'tweets': 534,\n",
       " 'errors': 534,\n",
       " 'diverse': 534,\n",
       " 'local': 533,\n",
       " 'develop': 531,\n",
       " 'multimodal': 531,\n",
       " 'translations': 529,\n",
       " 'predicting': 528,\n",
       " 'development': 525,\n",
       " 'being': 524,\n",
       " 'response': 522,\n",
       " 'key': 521,\n",
       " 'robust': 521,\n",
       " '2019': 520,\n",
       " 'recurrent': 518,\n",
       " 'mechanism': 518,\n",
       " 'build': 516,\n",
       " 'range': 514,\n",
       " 'strategies': 511,\n",
       " 'four': 510,\n",
       " 'requires': 509,\n",
       " 'downstream': 508,\n",
       " 'settings': 508,\n",
       " 'hierarchical': 507,\n",
       " 'expressions': 506,\n",
       " 'example': 506,\n",
       " 'original': 506,\n",
       " '5': 504,\n",
       " 'trees': 502,\n",
       " 'grained': 500,\n",
       " 'lstm': 499,\n",
       " 'arabic': 499,\n",
       " 'comprehension': 498,\n",
       " 'combination': 498,\n",
       " 'constraints': 498,\n",
       " '4': 495,\n",
       " 'vectors': 495,\n",
       " 'phrases': 493,\n",
       " 'goal': 492,\n",
       " 'bilingual': 491,\n",
       " 'because': 491,\n",
       " 'especially': 491,\n",
       " 'adaptation': 489,\n",
       " 'evaluating': 488,\n",
       " 'extensive': 488,\n",
       " 'syntax': 487,\n",
       " 'less': 486,\n",
       " 'distributional': 485,\n",
       " 'good': 484,\n",
       " 'class': 484,\n",
       " 'obtained': 483,\n",
       " 'jointly': 481,\n",
       " 'properties': 480,\n",
       " 'measure': 478,\n",
       " 'require': 478,\n",
       " 'term': 477,\n",
       " 'apply': 475,\n",
       " 'technique': 475,\n",
       " 'parameters': 474,\n",
       " 'application': 474,\n",
       " 'obtain': 474,\n",
       " 'web': 474,\n",
       " 'making': 472,\n",
       " 'developed': 472,\n",
       " 'difficult': 470,\n",
       " 'higher': 470,\n",
       " 'emotion': 468,\n",
       " 'aspects': 468,\n",
       " 'global': 468,\n",
       " 'base': 467,\n",
       " 'metric': 466,\n",
       " 'fact': 466,\n",
       " 'extract': 465,\n",
       " 'conversational': 465,\n",
       " 'distribution': 465,\n",
       " 'predictions': 460,\n",
       " 'furthermore': 460,\n",
       " 'should': 459,\n",
       " 'evaluated': 456,\n",
       " 'learns': 456,\n",
       " 'outperform': 456,\n",
       " 'us': 456,\n",
       " 'potential': 455,\n",
       " 'manually': 455,\n",
       " 'average': 454,\n",
       " 'effectively': 452,\n",
       " 'building': 452,\n",
       " 'linear': 451,\n",
       " 'main': 451,\n",
       " 'traditional': 450,\n",
       " 'responses': 450,\n",
       " 'function': 449,\n",
       " 'produce': 448,\n",
       " 'result': 446,\n",
       " 'extracted': 446,\n",
       " 'oriented': 446,\n",
       " 'individual': 445,\n",
       " 'summaries': 445,\n",
       " 'graphs': 445,\n",
       " 'disambiguation': 445,\n",
       " 'pair': 445,\n",
       " 'strategy': 444,\n",
       " 'contexts': 444,\n",
       " 'overall': 443,\n",
       " 'community': 442,\n",
       " 'points': 439,\n",
       " 'gender': 439,\n",
       " 'generalization': 438,\n",
       " 'query': 438,\n",
       " 'detecting': 437,\n",
       " 'reference': 435,\n",
       " 'report': 435,\n",
       " 'yet': 433,\n",
       " 'designed': 433,\n",
       " 'size': 433,\n",
       " 'subtask': 430,\n",
       " 'directly': 429,\n",
       " 'style': 429,\n",
       " 'grammatical': 428,\n",
       " 'makes': 428,\n",
       " 'aims': 428,\n",
       " 'comparable': 428,\n",
       " 'against': 426,\n",
       " 'made': 426,\n",
       " 'semi': 425,\n",
       " 'benchmarks': 424,\n",
       " 'ner': 424,\n",
       " 'sub': 423,\n",
       " 'highly': 423,\n",
       " '2018': 423,\n",
       " 'experiment': 421,\n",
       " '2016': 420,\n",
       " 'classifiers': 420,\n",
       " 'cases': 419,\n",
       " 'variety': 419,\n",
       " 'generative': 418,\n",
       " 'focused': 417,\n",
       " 'moreover': 416,\n",
       " 'known': 415,\n",
       " 'discuss': 415,\n",
       " 'architectures': 414,\n",
       " 'spoken': 414,\n",
       " 'answers': 414,\n",
       " 'topics': 414,\n",
       " 'since': 412,\n",
       " 'could': 412,\n",
       " 'analyze': 410,\n",
       " 'clinical': 409,\n",
       " 'top': 406,\n",
       " 'either': 406,\n",
       " 'combining': 405,\n",
       " 'correct': 404,\n",
       " 'objective': 404,\n",
       " 'medical': 404,\n",
       " 'typically': 403,\n",
       " 'abstract': 403,\n",
       " 'sources': 403,\n",
       " 'importance': 402,\n",
       " 'despite': 402,\n",
       " 'convolutional': 402,\n",
       " 'free': 402,\n",
       " 'create': 401,\n",
       " 'external': 401,\n",
       " 'driven': 400,\n",
       " '2017': 397,\n",
       " 'explicit': 397,\n",
       " 'lack': 397,\n",
       " 'arguments': 396,\n",
       " 'post': 396,\n",
       " 'written': 395,\n",
       " 'verb': 394,\n",
       " 'conversation': 394,\n",
       " 'grammars': 394,\n",
       " 'resulting': 394,\n",
       " 'differences': 393,\n",
       " 'consider': 393,\n",
       " 'complexity': 393,\n",
       " 'descriptions': 393,\n",
       " 'automated': 392,\n",
       " 'summary': 391,\n",
       " 'comparison': 391,\n",
       " 'issues': 390,\n",
       " 'concepts': 388,\n",
       " 'amount': 387,\n",
       " 're': 387,\n",
       " 'parsers': 387,\n",
       " 'https': 387,\n",
       " 'although': 385,\n",
       " 'mining': 385,\n",
       " 'augmentation': 385,\n",
       " 'performs': 384,\n",
       " 'found': 383,\n",
       " 'popular': 383,\n",
       " 'universal': 383,\n",
       " 'here': 383,\n",
       " 'components': 382,\n",
       " 'called': 382,\n",
       " 'vocabulary': 381,\n",
       " 'impact': 379,\n",
       " 'matching': 377,\n",
       " 'works': 375,\n",
       " 'humans': 375,\n",
       " 'coverage': 375,\n",
       " 'submission': 374,\n",
       " 'usually': 373,\n",
       " 'measures': 372,\n",
       " 'rely': 372,\n",
       " 'evaluations': 370,\n",
       " 'full': 370,\n",
       " 'issue': 369,\n",
       " 'conduct': 368,\n",
       " 'categories': 368,\n",
       " 'accurate': 365,\n",
       " 'rule': 365,\n",
       " '2020': 364,\n",
       " 'effect': 363,\n",
       " 'token': 363,\n",
       " 'commonsense': 362,\n",
       " 'instead': 362,\n",
       " 'f': 358,\n",
       " 'noisy': 356,\n",
       " 'tool': 356,\n",
       " 'take': 356,\n",
       " '–': 356,\n",
       " 'forms': 355,\n",
       " 'tools': 355,\n",
       " 'layer': 355,\n",
       " 'candidate': 354,\n",
       " 'mentions': 353,\n",
       " 'compositional': 353,\n",
       " 'instances': 352,\n",
       " 'conversations': 352,\n",
       " 'article': 352,\n",
       " 'suggest': 351,\n",
       " 'manual': 351,\n",
       " 'wikipedia': 351,\n",
       " 'github': 350,\n",
       " 'unseen': 349,\n",
       " 'images': 349,\n",
       " 'com': 349,\n",
       " 'hand': 349,\n",
       " 'understand': 349,\n",
       " 'utterances': 349,\n",
       " 'wide': 348,\n",
       " 'random': 348,\n",
       " 'tokens': 348,\n",
       " 'provided': 348,\n",
       " 'behavior': 348,\n",
       " 'publicly': 347,\n",
       " 'span': 346,\n",
       " 'articles': 346,\n",
       " 'therefore': 345,\n",
       " 'collection': 345,\n",
       " 'biomedical': 345,\n",
       " 'estimation': 345,\n",
       " 'represent': 345,\n",
       " 'loss': 344,\n",
       " 'independent': 343,\n",
       " 'implicit': 343,\n",
       " 'component': 342,\n",
       " 'years': 342,\n",
       " 'ensemble': 342,\n",
       " 'success': 341,\n",
       " 'dynamic': 341,\n",
       " 'negative': 341,\n",
       " 'sequences': 340,\n",
       " 'parse': 340,\n",
       " 'correlation': 339,\n",
       " 'previously': 339,\n",
       " 'correction': 338,\n",
       " 'people': 337,\n",
       " 'explicitly': 336,\n",
       " 'b': 336,\n",
       " 't': 335,\n",
       " 'noun': 335,\n",
       " 'amr': 335,\n",
       " 'consists': 333,\n",
       " 'pos': 333,\n",
       " 'detect': 332,\n",
       " 'treebank': 331,\n",
       " 'consistent': 330,\n",
       " 'encoding': 329,\n",
       " 'corresponding': 329,\n",
       " 'health': 329,\n",
       " 'probabilistic': 328,\n",
       " 'findings': 328,\n",
       " 'clustering': 327,\n",
       " 'literature': 327,\n",
       " 'concept': 326,\n",
       " 'structural': 326,\n",
       " 'widely': 326,\n",
       " 'promising': 325,\n",
       " 'respectively': 324,\n",
       " 'classes': 324,\n",
       " 'theory': 324,\n",
       " 'performing': 323,\n",
       " 'leads': 323,\n",
       " 'rather': 322,\n",
       " 'leverage': 322,\n",
       " 'pipeline': 320,\n",
       " 'scheme': 320,\n",
       " 'incorporate': 319,\n",
       " 'submitted': 317,\n",
       " 'fully': 317,\n",
       " 'layers': 316,\n",
       " 'account': 315,\n",
       " 'interaction': 315,\n",
       " 'contrast': 315,\n",
       " 'gap': 314,\n",
       " 'biases': 314,\n",
       " 'interest': 314,\n",
       " 'spanish': 314,\n",
       " '6': 314,\n",
       " 'slot': 313,\n",
       " 'relative': 313,\n",
       " 'finding': 313,\n",
       " 'contains': 312,\n",
       " 'levels': 312,\n",
       " 'writing': 312,\n",
       " 'final': 311,\n",
       " 'entailment': 311,\n",
       " 'according': 310,\n",
       " 'field': 310,\n",
       " 'researchers': 310,\n",
       " 'interpretation': 309,\n",
       " 'scientific': 309,\n",
       " 'interactions': 309,\n",
       " 'scoring': 309,\n",
       " 'progress': 308,\n",
       " 'conditional': 308,\n",
       " 'functions': 307,\n",
       " 'coherence': 307,\n",
       " 'leveraging': 307,\n",
       " 'alternative': 307,\n",
       " 'verbs': 306,\n",
       " 'incorporating': 306,\n",
       " 'gold': 306,\n",
       " 'logical': 306,\n",
       " 'subtasks': 305,\n",
       " 'combined': 305,\n",
       " 'length': 304,\n",
       " 'phenomena': 303,\n",
       " 'precision': 301,\n",
       " 'induction': 300,\n",
       " 'co': 299,\n",
       " 'include': 299,\n",
       " 'interactive': 299,\n",
       " 'showing': 299,\n",
       " 'change': 299,\n",
       " 'relationships': 298,\n",
       " 'robustness': 298,\n",
       " 'scenarios': 298,\n",
       " 'extracting': 298,\n",
       " 'practical': 298,\n",
       " 'ways': 298,\n",
       " 'dictionary': 297,\n",
       " 'enables': 297,\n",
       " 'unlabeled': 296,\n",
       " '10': 296,\n",
       " 'reduce': 296,\n",
       " 'unified': 296,\n",
       " 'aim': 296,\n",
       " 'description': 296,\n",
       " 'construct': 296,\n",
       " 'easily': 296,\n",
       " 'derived': 295,\n",
       " 'pretraining': 295,\n",
       " 'hard': 294,\n",
       " 'gains': 294,\n",
       " 'associated': 294,\n",
       " 'after': 294,\n",
       " 'noise': 294,\n",
       " 'stance': 294,\n",
       " 'transition': 294,\n",
       " 'opinion': 293,\n",
       " 'encode': 293,\n",
       " 'transformers': 293,\n",
       " 'reviews': 293,\n",
       " 's': 293,\n",
       " 'french': 293,\n",
       " 'major': 292,\n",
       " 'another': 292,\n",
       " 'grounded': 292,\n",
       " 'crucial': 292,\n",
       " 'control': 291,\n",
       " 'r': 291,\n",
       " 'contain': 291,\n",
       " 'cost': 291,\n",
       " 'ii': 290,\n",
       " 'exploit': 289,\n",
       " 'gram': 289,\n",
       " 'five': 288,\n",
       " 'achieving': 288,\n",
       " 'effects': 288,\n",
       " 'paraphrase': 286,\n",
       " 'little': 285,\n",
       " 'agreement': 284,\n",
       " 'lead': 284,\n",
       " 'positive': 284,\n",
       " 'providing': 283,\n",
       " 'along': 283,\n",
       " 'generates': 281,\n",
       " 'units': 281,\n",
       " '8': 281,\n",
       " 'point': 280,\n",
       " 'samples': 280,\n",
       " 'linking': 279,\n",
       " 'linguistics': 279,\n",
       " 'japanese': 279,\n",
       " 'underlying': 277,\n",
       " 'outputs': 277,\n",
       " 'tracking': 275,\n",
       " 'certain': 275,\n",
       " 'ones': 275,\n",
       " 'procedure': 275,\n",
       " 'back': 274,\n",
       " 'larger': 274,\n",
       " 'wmt': 274,\n",
       " 'distance': 273,\n",
       " 'nature': 273,\n",
       " 'factors': 272,\n",
       " 'would': 271,\n",
       " 'discriminative': 270,\n",
       " 'abstractive': 270,\n",
       " 'solution': 270,\n",
       " 'instance': 269,\n",
       " 'proposes': 269,\n",
       " 'far': 269,\n",
       " '2015': 268,\n",
       " 'become': 268,\n",
       " 'substantially': 267,\n",
       " 'together': 267,\n",
       " 'argue': 267,\n",
       " 'cannot': 266,\n",
       " '7': 266,\n",
       " 'applying': 266,\n",
       " 'policy': 266,\n",
       " 'review': 266,\n",
       " 'appropriate': 266,\n",
       " 'combines': 265,\n",
       " 'additionally': 265,\n",
       " 'ranked': 265,\n",
       " 'combine': 265,\n",
       " 'increase': 265,\n",
       " 'extend': 264,\n",
       " 'queries': 264,\n",
       " 'collected': 264,\n",
       " 'yields': 264,\n",
       " 'facts': 263,\n",
       " 'decision': 263,\n",
       " 'analyses': 263,\n",
       " 'built': 262,\n",
       " 'stage': 262,\n",
       " 'rnn': 262,\n",
       " 'reinforcement': 262,\n",
       " 'cnn': 261,\n",
       " 'utterance': 261,\n",
       " 'benefit': 261,\n",
       " 'diversity': 261,\n",
       " 'feedback': 261,\n",
       " 'required': 261,\n",
       " 'construction': 259,\n",
       " 'contextualized': 259,\n",
       " 'binary': 258,\n",
       " 'surface': 258,\n",
       " 'recall': 257,\n",
       " 'sensitive': 257,\n",
       " 'particularly': 257,\n",
       " 'respect': 257,\n",
       " 'beyond': 257,\n",
       " 'smt': 256,\n",
       " 'comparing': 255,\n",
       " 'polarity': 255,\n",
       " 'choice': 255,\n",
       " 'release': 254,\n",
       " 'paradigm': 254,\n",
       " 'presented': 254,\n",
       " 'explanations': 253,\n",
       " 'rank': 252,\n",
       " 'solve': 252,\n",
       " 'head': 252,\n",
       " 'continuous': 252,\n",
       " 'module': 251,\n",
       " 'participants': 251,\n",
       " 'defined': 250,\n",
       " 'c': 250,\n",
       " 'frame': 250,\n",
       " 'claims': 249,\n",
       " 'hidden': 249,\n",
       " 'team': 249,\n",
       " 'view': 248,\n",
       " 'mapping': 248,\n",
       " 'hybrid': 247,\n",
       " 'created': 246,\n",
       " 'essential': 246,\n",
       " 'frequency': 245,\n",
       " 'probability': 245,\n",
       " 'efficiency': 245,\n",
       " 'nli': 244,\n",
       " 'select': 244,\n",
       " 'exploiting': 244,\n",
       " 'inter': 243,\n",
       " 'computer': 243,\n",
       " 'consistency': 243,\n",
       " 'mixed': 243,\n",
       " 'examine': 243,\n",
       " 'hypothesis': 243,\n",
       " 'relational': 242,\n",
       " 'easy': 242,\n",
       " 'introduced': 241,\n",
       " 'public': 241,\n",
       " 'sequential': 241,\n",
       " 'relevance': 241,\n",
       " 'substantial': 240,\n",
       " 'reported': 240,\n",
       " 'distributions': 240,\n",
       " 'tuned': 239,\n",
       " 'following': 239,\n",
       " 'synthetic': 238,\n",
       " 'turn': 238,\n",
       " 'means': 238,\n",
       " 'motivated': 237,\n",
       " 'semantically': 237,\n",
       " 'modal': 237,\n",
       " 'sampling': 236,\n",
       " 'purpose': 236,\n",
       " 'basic': 235,\n",
       " 'native': 235,\n",
       " 'advantage': 235,\n",
       " 'decisions': 235,\n",
       " 'next': 235,\n",
       " 'indicate': 234,\n",
       " 'candidates': 233,\n",
       " 'off': 233,\n",
       " 'position': 233,\n",
       " ...}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldic = getdictionary(train_file)\n",
    "sorteddic = {k: v for k, v in sorted(fulldic.items(), \n",
    "                                     key=lambda item: item[1],\n",
    "                                     reverse=True)}\n",
    "sorteddic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32347"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorteddic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0,\n",
       " 'of': 1,\n",
       " 'and': 2,\n",
       " 'a': 3,\n",
       " 'to': 4,\n",
       " 'in': 5,\n",
       " 'we': 6,\n",
       " 'for': 7,\n",
       " 'on': 8,\n",
       " 'that': 9,\n",
       " 'is': 10,\n",
       " 'this': 11,\n",
       " 'with': 12,\n",
       " 'our': 13,\n",
       " 'model': 14,\n",
       " 'as': 15,\n",
       " 'language': 16,\n",
       " 'are': 17,\n",
       " 'from': 18,\n",
       " 'by': 19,\n",
       " 'models': 20,\n",
       " 'task': 21,\n",
       " 'an': 22,\n",
       " 'based': 23,\n",
       " 'data': 24,\n",
       " 'which': 25,\n",
       " 'can': 26,\n",
       " 'learning': 27,\n",
       " 'text': 28,\n",
       " 'word': 29,\n",
       " 'paper': 30,\n",
       " 'be': 31,\n",
       " 'using': 32,\n",
       " 'translation': 33,\n",
       " 'neural': 34,\n",
       " 'show': 35,\n",
       " 'system': 36,\n",
       " 'results': 37,\n",
       " 'training': 38,\n",
       " 'it': 39,\n",
       " 'approach': 40,\n",
       " 'performance': 41,\n",
       " 'information': 42,\n",
       " 'tasks': 43,\n",
       " 'two': 44,\n",
       " 'or': 45,\n",
       " 'propose': 46,\n",
       " 'semantic': 47,\n",
       " 'such': 48,\n",
       " 'these': 49,\n",
       " 'at': 50,\n",
       " 'knowledge': 51,\n",
       " 'method': 52,\n",
       " 'state': 53,\n",
       " 'have': 54,\n",
       " 'not': 55,\n",
       " 'different': 56,\n",
       " 'machine': 57,\n",
       " 'systems': 58,\n",
       " 'methods': 59,\n",
       " 'work': 60,\n",
       " 'new': 61,\n",
       " 'languages': 62,\n",
       " 'more': 63,\n",
       " 'domain': 64,\n",
       " 'also': 65,\n",
       " 'has': 66,\n",
       " 'between': 67,\n",
       " 'sentence': 68,\n",
       " 'present': 69,\n",
       " 'both': 70,\n",
       " 'art': 71,\n",
       " 'their': 72,\n",
       " 'use': 73,\n",
       " 'english': 74,\n",
       " 'dataset': 75,\n",
       " 'evaluation': 76,\n",
       " 'features': 77,\n",
       " 'natural': 78,\n",
       " 'human': 79,\n",
       " 'over': 80,\n",
       " 'generation': 81,\n",
       " 'used': 82,\n",
       " 'analysis': 83,\n",
       " 'words': 84,\n",
       " 'level': 85,\n",
       " 'corpus': 86,\n",
       " 'datasets': 87,\n",
       " 'trained': 88,\n",
       " 'into': 89,\n",
       " 'representations': 90,\n",
       " 'large': 91,\n",
       " 'experiments': 92,\n",
       " 'parsing': 93,\n",
       " 'context': 94,\n",
       " 'embeddings': 95,\n",
       " 'however': 96,\n",
       " 'classification': 97,\n",
       " 'but': 98,\n",
       " 'multi': 99,\n",
       " 'proposed': 100,\n",
       " 'first': 101,\n",
       " 'question': 102,\n",
       " 'one': 103,\n",
       " 'been': 104,\n",
       " 'than': 105,\n",
       " 'well': 106,\n",
       " 'e': 107,\n",
       " 'how': 108,\n",
       " 'set': 109,\n",
       " 'while': 110,\n",
       " 'novel': 111,\n",
       " 'only': 112,\n",
       " 'each': 113,\n",
       " 'when': 114,\n",
       " 'other': 115,\n",
       " 'attention': 116,\n",
       " 'problem': 117,\n",
       " 'nlp': 118,\n",
       " 'existing': 119,\n",
       " 'framework': 120,\n",
       " 'sentences': 121,\n",
       " 'cross': 122,\n",
       " 'approaches': 123,\n",
       " 'all': 124,\n",
       " 'network': 125,\n",
       " 'pre': 126,\n",
       " 'sequence': 127,\n",
       " 'representation': 128,\n",
       " 'quality': 129,\n",
       " 'its': 130,\n",
       " 'entity': 131,\n",
       " '1': 132,\n",
       " 'sentiment': 133,\n",
       " 'linguistic': 134,\n",
       " 'dialogue': 135,\n",
       " 'research': 136,\n",
       " 'target': 137,\n",
       " 'extraction': 138,\n",
       " 'detection': 139,\n",
       " 'they': 140,\n",
       " 'better': 141,\n",
       " 'study': 142,\n",
       " 'most': 143,\n",
       " 'shared': 144,\n",
       " 'source': 145,\n",
       " 'i': 146,\n",
       " 'previous': 147,\n",
       " 'demonstrate': 148,\n",
       " 'time': 149,\n",
       " 'automatic': 150,\n",
       " 'accuracy': 151,\n",
       " 'document': 152,\n",
       " 'multiple': 153,\n",
       " 'speech': 154,\n",
       " 'processing': 155,\n",
       " 'syntactic': 156,\n",
       " 'dependency': 157,\n",
       " 'graph': 158,\n",
       " 'lexical': 159,\n",
       " 'end': 160,\n",
       " 'best': 161,\n",
       " 'three': 162,\n",
       " 'input': 163,\n",
       " 'specific': 164,\n",
       " 'then': 165,\n",
       " 'supervised': 166,\n",
       " 'structure': 167,\n",
       " 'where': 168,\n",
       " 'several': 169,\n",
       " 'multilingual': 170,\n",
       " 'available': 171,\n",
       " 'improve': 172,\n",
       " 'given': 173,\n",
       " 'across': 174,\n",
       " '2': 175,\n",
       " 'introduce': 176,\n",
       " 'discourse': 177,\n",
       " 'many': 178,\n",
       " 'relations': 179,\n",
       " 'non': 180,\n",
       " 'corpora': 181,\n",
       " 'further': 182,\n",
       " 'high': 183,\n",
       " 'test': 184,\n",
       " 'modeling': 185,\n",
       " 'similarity': 186,\n",
       " 'simple': 187,\n",
       " 'outperforms': 188,\n",
       " 'recent': 189,\n",
       " 'annotation': 190,\n",
       " 'understanding': 191,\n",
       " 'questions': 192,\n",
       " 'user': 193,\n",
       " 'fine': 194,\n",
       " 'relation': 195,\n",
       " 'networks': 196,\n",
       " 'find': 197,\n",
       " 'prediction': 198,\n",
       " 'them': 199,\n",
       " 'bert': 200,\n",
       " 'unsupervised': 201,\n",
       " 'resource': 202,\n",
       " 'pairs': 203,\n",
       " 'about': 204,\n",
       " 'order': 205,\n",
       " 'evaluate': 206,\n",
       " 'some': 207,\n",
       " 'g': 208,\n",
       " 'through': 209,\n",
       " 'deep': 210,\n",
       " 'summarization': 211,\n",
       " 'without': 212,\n",
       " 'provide': 213,\n",
       " 'social': 214,\n",
       " 'low': 215,\n",
       " 'baseline': 216,\n",
       " 'annotated': 217,\n",
       " 'algorithm': 218,\n",
       " 'automatically': 219,\n",
       " 'standard': 220,\n",
       " 'learn': 221,\n",
       " 'event': 222,\n",
       " 'texts': 223,\n",
       " 'semeval': 224,\n",
       " 'answering': 225,\n",
       " 'transfer': 226,\n",
       " 'score': 227,\n",
       " 'inference': 228,\n",
       " 'various': 229,\n",
       " 'achieves': 230,\n",
       " 'effective': 231,\n",
       " 'experimental': 232,\n",
       " 'lingual': 233,\n",
       " 'generated': 234,\n",
       " 'often': 235,\n",
       " 'scale': 236,\n",
       " 'embedding': 237,\n",
       " 'types': 238,\n",
       " 'significantly': 239,\n",
       " 'techniques': 240,\n",
       " 'generate': 241,\n",
       " 'transformer': 242,\n",
       " 'process': 243,\n",
       " 'via': 244,\n",
       " 'important': 245,\n",
       " 'answer': 246,\n",
       " 'chinese': 247,\n",
       " 'feature': 248,\n",
       " 'same': 249,\n",
       " 'do': 250,\n",
       " 'open': 251,\n",
       " 'number': 252,\n",
       " 'news': 253,\n",
       " 'including': 254,\n",
       " 'out': 255,\n",
       " 'recognition': 256,\n",
       " 'entities': 257,\n",
       " 'al': 258,\n",
       " 'reasoning': 259,\n",
       " 'there': 260,\n",
       " '0': 261,\n",
       " 'code': 262,\n",
       " 'parser': 263,\n",
       " 'terms': 264,\n",
       " 'single': 265,\n",
       " 'parallel': 266,\n",
       " 'content': 267,\n",
       " 'describe': 268,\n",
       " 'topic': 269,\n",
       " 'achieve': 270,\n",
       " 'was': 271,\n",
       " 'et': 272,\n",
       " 'complex': 273,\n",
       " 'space': 274,\n",
       " 'metrics': 275,\n",
       " 'domains': 276,\n",
       " 'statistical': 277,\n",
       " 'benchmark': 278,\n",
       " 'related': 279,\n",
       " 'may': 280,\n",
       " 'architecture': 281,\n",
       " 'strong': 282,\n",
       " 'meaning': 283,\n",
       " 'train': 284,\n",
       " 'compared': 285,\n",
       " 'baselines': 286,\n",
       " 'tree': 287,\n",
       " 'current': 288,\n",
       " 'any': 289,\n",
       " 'improvements': 290,\n",
       " 'perform': 291,\n",
       " 'significant': 292,\n",
       " 'documents': 293,\n",
       " 'search': 294,\n",
       " 'identification': 295,\n",
       " 'up': 296,\n",
       " 'even': 297,\n",
       " 'computational': 298,\n",
       " 'will': 299,\n",
       " 'nmt': 300,\n",
       " 'applications': 301,\n",
       " 'general': 302,\n",
       " 'part': 303,\n",
       " 'long': 304,\n",
       " 'error': 305,\n",
       " 'media': 306,\n",
       " 'output': 307,\n",
       " 'investigate': 308,\n",
       " 'f1': 309,\n",
       " 'second': 310,\n",
       " 'improves': 311,\n",
       " 'address': 312,\n",
       " 'describes': 313,\n",
       " 'named': 314,\n",
       " 'sense': 315,\n",
       " 'resources': 316,\n",
       " 'make': 317,\n",
       " 'phrase': 318,\n",
       " 'structures': 319,\n",
       " 'real': 320,\n",
       " 'challenging': 321,\n",
       " 'retrieval': 322,\n",
       " 'shot': 323,\n",
       " 'focus': 324,\n",
       " 'textual': 325,\n",
       " 'identify': 326,\n",
       " 'explore': 327,\n",
       " 'scores': 328,\n",
       " 'self': 329,\n",
       " 'what': 330,\n",
       " 'challenge': 331,\n",
       " 'semantics': 332,\n",
       " 'encoder': 333,\n",
       " 'vector': 334,\n",
       " '3': 335,\n",
       " 'uses': 336,\n",
       " 'very': 337,\n",
       " 'generating': 338,\n",
       " 'morphological': 339,\n",
       " 'improvement': 340,\n",
       " 'labels': 341,\n",
       " 'few': 342,\n",
       " 'alignment': 343,\n",
       " 'examples': 344,\n",
       " 'capture': 345,\n",
       " 'way': 346,\n",
       " 'presents': 347,\n",
       " 'small': 348,\n",
       " 'latent': 349,\n",
       " 'form': 350,\n",
       " 'no': 351,\n",
       " 'online': 352,\n",
       " 'grammar': 353,\n",
       " 'evidence': 354,\n",
       " 'effectiveness': 355,\n",
       " 'users': 356,\n",
       " 'selection': 357,\n",
       " 'like': 358,\n",
       " 'role': 359,\n",
       " 'shown': 360,\n",
       " 'similar': 361,\n",
       " 'label': 362,\n",
       " 'achieved': 363,\n",
       " 'n': 364,\n",
       " 'studies': 365,\n",
       " 'tuning': 366,\n",
       " 'learned': 367,\n",
       " 'world': 368,\n",
       " 'character': 369,\n",
       " 'within': 370,\n",
       " 'sets': 371,\n",
       " 'were': 372,\n",
       " 'structured': 373,\n",
       " 'does': 374,\n",
       " 'particular': 375,\n",
       " 'qa': 376,\n",
       " 'events': 377,\n",
       " 'common': 378,\n",
       " 'case': 379,\n",
       " 'due': 380,\n",
       " 'among': 381,\n",
       " 'so': 382,\n",
       " 'efficient': 383,\n",
       " 'addition': 384,\n",
       " 'whether': 385,\n",
       " 'limited': 386,\n",
       " 'decoder': 387,\n",
       " 'additional': 388,\n",
       " 'annotations': 389,\n",
       " 'bleu': 390,\n",
       " 'relevant': 391,\n",
       " 'joint': 392,\n",
       " 'type': 393,\n",
       " 'towards': 394,\n",
       " 'during': 395,\n",
       " 'reading': 396,\n",
       " 'predict': 397,\n",
       " 'bias': 398,\n",
       " 'coreference': 399,\n",
       " 'thus': 400,\n",
       " 'german': 401,\n",
       " 'shows': 402,\n",
       " 'improving': 403,\n",
       " 'dialog': 404,\n",
       " 'compare': 405,\n",
       " 'tagging': 406,\n",
       " 'algorithms': 407,\n",
       " 'applied': 408,\n",
       " 'provides': 409,\n",
       " 'possible': 410,\n",
       " 'aspect': 411,\n",
       " 'visual': 412,\n",
       " 'argument': 413,\n",
       " 'under': 414,\n",
       " 'able': 415,\n",
       " 'adversarial': 416,\n",
       " 'problems': 417,\n",
       " 'temporal': 418,\n",
       " 'labeled': 419,\n",
       " 'prior': 420,\n",
       " 'finally': 421,\n",
       " 'resolution': 422,\n",
       " 'patterns': 423,\n",
       " 'recently': 424,\n",
       " 'monolingual': 425,\n",
       " 'mt': 426,\n",
       " 'rules': 427,\n",
       " 'labeling': 428,\n",
       " 'support': 429,\n",
       " 'identifying': 430,\n",
       " 'those': 431,\n",
       " 'allows': 432,\n",
       " 'memory': 433,\n",
       " 'classifier': 434,\n",
       " 'need': 435,\n",
       " 'help': 436,\n",
       " 'dependencies': 437,\n",
       " 'supervision': 438,\n",
       " 'rich': 439,\n",
       " 'specifically': 440,\n",
       " 'twitter': 441,\n",
       " 'contextual': 442,\n",
       " 'setting': 443,\n",
       " 'segmentation': 444,\n",
       " 'ranking': 445,\n",
       " 'future': 446,\n",
       " 'ability': 447,\n",
       " 'useful': 448,\n",
       " 'image': 449,\n",
       " 'step': 450,\n",
       " 'aware': 451,\n",
       " 'decoding': 452,\n",
       " 'lexicon': 453,\n",
       " 'pretrained': 454,\n",
       " 'competitive': 455,\n",
       " 'zero': 456,\n",
       " 'design': 457,\n",
       " 'much': 458,\n",
       " 'empirical': 459,\n",
       " 'improved': 460,\n",
       " 'short': 461,\n",
       " 'challenges': 462,\n",
       " 'still': 463,\n",
       " 'if': 464,\n",
       " 'tweets': 465,\n",
       " 'errors': 466,\n",
       " 'diverse': 467,\n",
       " 'local': 468,\n",
       " 'develop': 469,\n",
       " 'multimodal': 470,\n",
       " 'translations': 471,\n",
       " 'predicting': 472,\n",
       " 'development': 473,\n",
       " 'being': 474,\n",
       " 'response': 475,\n",
       " 'key': 476,\n",
       " 'robust': 477,\n",
       " '2019': 478,\n",
       " 'recurrent': 479,\n",
       " 'mechanism': 480,\n",
       " 'build': 481,\n",
       " 'range': 482,\n",
       " 'strategies': 483,\n",
       " 'four': 484,\n",
       " 'requires': 485,\n",
       " 'downstream': 486,\n",
       " 'settings': 487,\n",
       " 'hierarchical': 488,\n",
       " 'expressions': 489,\n",
       " 'example': 490,\n",
       " 'original': 491,\n",
       " '5': 492,\n",
       " 'trees': 493,\n",
       " 'grained': 494,\n",
       " 'lstm': 495,\n",
       " 'arabic': 496,\n",
       " 'comprehension': 497,\n",
       " 'combination': 498,\n",
       " 'constraints': 499,\n",
       " '4': 500,\n",
       " 'vectors': 501,\n",
       " 'phrases': 502,\n",
       " 'goal': 503,\n",
       " 'bilingual': 504,\n",
       " 'because': 505,\n",
       " 'especially': 506,\n",
       " 'adaptation': 507,\n",
       " 'evaluating': 508,\n",
       " 'extensive': 509,\n",
       " 'syntax': 510,\n",
       " 'less': 511,\n",
       " 'distributional': 512,\n",
       " 'good': 513,\n",
       " 'class': 514,\n",
       " 'obtained': 515,\n",
       " 'jointly': 516,\n",
       " 'properties': 517,\n",
       " 'measure': 518,\n",
       " 'require': 519,\n",
       " 'term': 520,\n",
       " 'apply': 521,\n",
       " 'technique': 522,\n",
       " 'parameters': 523,\n",
       " 'application': 524,\n",
       " 'obtain': 525,\n",
       " 'web': 526,\n",
       " 'making': 527,\n",
       " 'developed': 528,\n",
       " 'difficult': 529,\n",
       " 'higher': 530,\n",
       " 'emotion': 531,\n",
       " 'aspects': 532,\n",
       " 'global': 533,\n",
       " 'base': 534,\n",
       " 'metric': 535,\n",
       " 'fact': 536,\n",
       " 'extract': 537,\n",
       " 'conversational': 538,\n",
       " 'distribution': 539,\n",
       " 'predictions': 540,\n",
       " 'furthermore': 541,\n",
       " 'should': 542,\n",
       " 'evaluated': 543,\n",
       " 'learns': 544,\n",
       " 'outperform': 545,\n",
       " 'us': 546,\n",
       " 'potential': 547,\n",
       " 'manually': 548,\n",
       " 'average': 549,\n",
       " 'effectively': 550,\n",
       " 'building': 551,\n",
       " 'linear': 552,\n",
       " 'main': 553,\n",
       " 'traditional': 554,\n",
       " 'responses': 555,\n",
       " 'function': 556,\n",
       " 'produce': 557,\n",
       " 'result': 558,\n",
       " 'extracted': 559,\n",
       " 'oriented': 560,\n",
       " 'individual': 561,\n",
       " 'summaries': 562,\n",
       " 'graphs': 563,\n",
       " 'disambiguation': 564,\n",
       " 'pair': 565,\n",
       " 'strategy': 566,\n",
       " 'contexts': 567,\n",
       " 'overall': 568,\n",
       " 'community': 569,\n",
       " 'points': 570,\n",
       " 'gender': 571,\n",
       " 'generalization': 572,\n",
       " 'query': 573,\n",
       " 'detecting': 574,\n",
       " 'reference': 575,\n",
       " 'report': 576,\n",
       " 'yet': 577,\n",
       " 'designed': 578,\n",
       " 'size': 579,\n",
       " 'subtask': 580,\n",
       " 'directly': 581,\n",
       " 'style': 582,\n",
       " 'grammatical': 583,\n",
       " 'makes': 584,\n",
       " 'aims': 585,\n",
       " 'comparable': 586,\n",
       " 'against': 587,\n",
       " 'made': 588,\n",
       " 'semi': 589,\n",
       " 'benchmarks': 590,\n",
       " 'ner': 591,\n",
       " 'sub': 592,\n",
       " 'highly': 593,\n",
       " '2018': 594,\n",
       " 'experiment': 595,\n",
       " '2016': 596,\n",
       " 'classifiers': 597,\n",
       " 'cases': 598,\n",
       " 'variety': 599,\n",
       " 'generative': 600,\n",
       " 'focused': 601,\n",
       " 'moreover': 602,\n",
       " 'known': 603,\n",
       " 'discuss': 604,\n",
       " 'architectures': 605,\n",
       " 'spoken': 606,\n",
       " 'answers': 607,\n",
       " 'topics': 608,\n",
       " 'since': 609,\n",
       " 'could': 610,\n",
       " 'analyze': 611,\n",
       " 'clinical': 612,\n",
       " 'top': 613,\n",
       " 'either': 614,\n",
       " 'combining': 615,\n",
       " 'correct': 616,\n",
       " 'objective': 617,\n",
       " 'medical': 618,\n",
       " 'typically': 619,\n",
       " 'abstract': 620,\n",
       " 'sources': 621,\n",
       " 'importance': 622,\n",
       " 'despite': 623,\n",
       " 'convolutional': 624,\n",
       " 'free': 625,\n",
       " 'create': 626,\n",
       " 'external': 627,\n",
       " 'driven': 628,\n",
       " '2017': 629,\n",
       " 'explicit': 630,\n",
       " 'lack': 631,\n",
       " 'arguments': 632,\n",
       " 'post': 633,\n",
       " 'written': 634,\n",
       " 'verb': 635,\n",
       " 'conversation': 636,\n",
       " 'grammars': 637,\n",
       " 'resulting': 638,\n",
       " 'differences': 639,\n",
       " 'consider': 640,\n",
       " 'complexity': 641,\n",
       " 'descriptions': 642,\n",
       " 'automated': 643,\n",
       " 'summary': 644,\n",
       " 'comparison': 645,\n",
       " 'issues': 646,\n",
       " 'concepts': 647,\n",
       " 'amount': 648,\n",
       " 're': 649,\n",
       " 'parsers': 650,\n",
       " 'https': 651,\n",
       " 'although': 652,\n",
       " 'mining': 653,\n",
       " 'augmentation': 654,\n",
       " 'performs': 655,\n",
       " 'found': 656,\n",
       " 'popular': 657,\n",
       " 'universal': 658,\n",
       " 'here': 659,\n",
       " 'components': 660,\n",
       " 'called': 661,\n",
       " 'vocabulary': 662,\n",
       " 'impact': 663,\n",
       " 'matching': 664,\n",
       " 'works': 665,\n",
       " 'humans': 666,\n",
       " 'coverage': 667,\n",
       " 'submission': 668,\n",
       " 'usually': 669,\n",
       " 'measures': 670,\n",
       " 'rely': 671,\n",
       " 'evaluations': 672,\n",
       " 'full': 673,\n",
       " 'issue': 674,\n",
       " 'conduct': 675,\n",
       " 'categories': 676,\n",
       " 'accurate': 677,\n",
       " 'rule': 678,\n",
       " '2020': 679,\n",
       " 'effect': 680,\n",
       " 'token': 681,\n",
       " 'commonsense': 682,\n",
       " 'instead': 683,\n",
       " 'f': 684,\n",
       " 'noisy': 685,\n",
       " 'tool': 686,\n",
       " 'take': 687,\n",
       " '–': 688,\n",
       " 'forms': 689,\n",
       " 'tools': 690,\n",
       " 'layer': 691,\n",
       " 'candidate': 692,\n",
       " 'mentions': 693,\n",
       " 'compositional': 694,\n",
       " 'instances': 695,\n",
       " 'conversations': 696,\n",
       " 'article': 697,\n",
       " 'suggest': 698,\n",
       " 'manual': 699,\n",
       " 'wikipedia': 700,\n",
       " 'github': 701,\n",
       " 'unseen': 702,\n",
       " 'images': 703,\n",
       " 'com': 704,\n",
       " 'hand': 705,\n",
       " 'understand': 706,\n",
       " 'utterances': 707,\n",
       " 'wide': 708,\n",
       " 'random': 709,\n",
       " 'tokens': 710,\n",
       " 'provided': 711,\n",
       " 'behavior': 712,\n",
       " 'publicly': 713,\n",
       " 'span': 714,\n",
       " 'articles': 715,\n",
       " 'therefore': 716,\n",
       " 'collection': 717,\n",
       " 'biomedical': 718,\n",
       " 'estimation': 719,\n",
       " 'represent': 720,\n",
       " 'loss': 721,\n",
       " 'independent': 722,\n",
       " 'implicit': 723,\n",
       " 'component': 724,\n",
       " 'years': 725,\n",
       " 'ensemble': 726,\n",
       " 'success': 727,\n",
       " 'dynamic': 728,\n",
       " 'negative': 729,\n",
       " 'sequences': 730,\n",
       " 'parse': 731,\n",
       " 'correlation': 732,\n",
       " 'previously': 733,\n",
       " 'correction': 734,\n",
       " 'people': 735,\n",
       " 'explicitly': 736,\n",
       " 'b': 737,\n",
       " 't': 738,\n",
       " 'noun': 739,\n",
       " 'amr': 740,\n",
       " 'consists': 741,\n",
       " 'pos': 742,\n",
       " 'detect': 743,\n",
       " 'treebank': 744,\n",
       " 'consistent': 745,\n",
       " 'encoding': 746,\n",
       " 'corresponding': 747,\n",
       " 'health': 748,\n",
       " 'probabilistic': 749,\n",
       " 'findings': 750,\n",
       " 'clustering': 751,\n",
       " 'literature': 752,\n",
       " 'concept': 753,\n",
       " 'structural': 754,\n",
       " 'widely': 755,\n",
       " 'promising': 756,\n",
       " 'respectively': 757,\n",
       " 'classes': 758,\n",
       " 'theory': 759,\n",
       " 'performing': 760,\n",
       " 'leads': 761,\n",
       " 'rather': 762,\n",
       " 'leverage': 763,\n",
       " 'pipeline': 764,\n",
       " 'scheme': 765,\n",
       " 'incorporate': 766,\n",
       " 'submitted': 767,\n",
       " 'fully': 768,\n",
       " 'layers': 769,\n",
       " 'account': 770,\n",
       " 'interaction': 771,\n",
       " 'contrast': 772,\n",
       " 'gap': 773,\n",
       " 'biases': 774,\n",
       " 'interest': 775,\n",
       " 'spanish': 776,\n",
       " '6': 777,\n",
       " 'slot': 778,\n",
       " 'relative': 779,\n",
       " 'finding': 780,\n",
       " 'contains': 781,\n",
       " 'levels': 782,\n",
       " 'writing': 783,\n",
       " 'final': 784,\n",
       " 'entailment': 785,\n",
       " 'according': 786,\n",
       " 'field': 787,\n",
       " 'researchers': 788,\n",
       " 'interpretation': 789,\n",
       " 'scientific': 790,\n",
       " 'interactions': 791,\n",
       " 'scoring': 792,\n",
       " 'progress': 793,\n",
       " 'conditional': 794,\n",
       " 'functions': 795,\n",
       " 'coherence': 796,\n",
       " 'leveraging': 797,\n",
       " 'alternative': 798,\n",
       " 'verbs': 799,\n",
       " 'incorporating': 800,\n",
       " 'gold': 801,\n",
       " 'logical': 802,\n",
       " 'subtasks': 803,\n",
       " 'combined': 804,\n",
       " 'length': 805,\n",
       " 'phenomena': 806,\n",
       " 'precision': 807,\n",
       " 'induction': 808,\n",
       " 'co': 809,\n",
       " 'include': 810,\n",
       " 'interactive': 811,\n",
       " 'showing': 812,\n",
       " 'change': 813,\n",
       " 'relationships': 814,\n",
       " 'robustness': 815,\n",
       " 'scenarios': 816,\n",
       " 'extracting': 817,\n",
       " 'practical': 818,\n",
       " 'ways': 819,\n",
       " 'dictionary': 820,\n",
       " 'enables': 821,\n",
       " 'unlabeled': 822,\n",
       " '10': 823,\n",
       " 'reduce': 824,\n",
       " 'unified': 825,\n",
       " 'aim': 826,\n",
       " 'description': 827,\n",
       " 'construct': 828,\n",
       " 'easily': 829,\n",
       " 'derived': 830,\n",
       " 'pretraining': 831,\n",
       " 'hard': 832,\n",
       " 'gains': 833,\n",
       " 'associated': 834,\n",
       " 'after': 835,\n",
       " 'noise': 836,\n",
       " 'stance': 837,\n",
       " 'transition': 838,\n",
       " 'opinion': 839,\n",
       " 'encode': 840,\n",
       " 'transformers': 841,\n",
       " 'reviews': 842,\n",
       " 's': 843,\n",
       " 'french': 844,\n",
       " 'major': 845,\n",
       " 'another': 846,\n",
       " 'grounded': 847,\n",
       " 'crucial': 848,\n",
       " 'control': 849,\n",
       " 'r': 850,\n",
       " 'contain': 851,\n",
       " 'cost': 852,\n",
       " 'ii': 853,\n",
       " 'exploit': 854,\n",
       " 'gram': 855,\n",
       " 'five': 856,\n",
       " 'achieving': 857,\n",
       " 'effects': 858,\n",
       " 'paraphrase': 859,\n",
       " 'little': 860,\n",
       " 'agreement': 861,\n",
       " 'lead': 862,\n",
       " 'positive': 863,\n",
       " 'providing': 864,\n",
       " 'along': 865,\n",
       " 'generates': 866,\n",
       " 'units': 867,\n",
       " '8': 868,\n",
       " 'point': 869,\n",
       " 'samples': 870,\n",
       " 'linking': 871,\n",
       " 'linguistics': 872,\n",
       " 'japanese': 873,\n",
       " 'underlying': 874,\n",
       " 'outputs': 875,\n",
       " 'tracking': 876,\n",
       " 'certain': 877,\n",
       " 'ones': 878,\n",
       " 'procedure': 879,\n",
       " 'back': 880,\n",
       " 'larger': 881,\n",
       " 'wmt': 882,\n",
       " 'distance': 883,\n",
       " 'nature': 884,\n",
       " 'factors': 885,\n",
       " 'would': 886,\n",
       " 'discriminative': 887,\n",
       " 'abstractive': 888,\n",
       " 'solution': 889,\n",
       " 'instance': 890,\n",
       " 'proposes': 891,\n",
       " 'far': 892,\n",
       " '2015': 893,\n",
       " 'become': 894,\n",
       " 'substantially': 895,\n",
       " 'together': 896,\n",
       " 'argue': 897,\n",
       " 'cannot': 898,\n",
       " '7': 899,\n",
       " 'applying': 900,\n",
       " 'policy': 901,\n",
       " 'review': 902,\n",
       " 'appropriate': 903,\n",
       " 'combines': 904,\n",
       " 'additionally': 905,\n",
       " 'ranked': 906,\n",
       " 'combine': 907,\n",
       " 'increase': 908,\n",
       " 'extend': 909,\n",
       " 'queries': 910,\n",
       " 'collected': 911,\n",
       " 'yields': 912,\n",
       " 'facts': 913,\n",
       " 'decision': 914,\n",
       " 'analyses': 915,\n",
       " 'built': 916,\n",
       " 'stage': 917,\n",
       " 'rnn': 918,\n",
       " 'reinforcement': 919,\n",
       " 'cnn': 920,\n",
       " 'utterance': 921,\n",
       " 'benefit': 922,\n",
       " 'diversity': 923,\n",
       " 'feedback': 924,\n",
       " 'required': 925,\n",
       " 'construction': 926,\n",
       " 'contextualized': 927,\n",
       " 'binary': 928,\n",
       " 'surface': 929,\n",
       " 'recall': 930,\n",
       " 'sensitive': 931,\n",
       " 'particularly': 932,\n",
       " 'respect': 933,\n",
       " 'beyond': 934,\n",
       " 'smt': 935,\n",
       " 'comparing': 936,\n",
       " 'polarity': 937,\n",
       " 'choice': 938,\n",
       " 'release': 939,\n",
       " 'paradigm': 940,\n",
       " 'presented': 941,\n",
       " 'explanations': 942,\n",
       " 'rank': 943,\n",
       " 'solve': 944,\n",
       " 'head': 945,\n",
       " 'continuous': 946,\n",
       " 'module': 947,\n",
       " 'participants': 948,\n",
       " 'defined': 949,\n",
       " 'c': 950,\n",
       " 'frame': 951,\n",
       " 'claims': 952,\n",
       " 'hidden': 953,\n",
       " 'team': 954,\n",
       " 'view': 955,\n",
       " 'mapping': 956,\n",
       " 'hybrid': 957,\n",
       " 'created': 958,\n",
       " 'essential': 959,\n",
       " 'frequency': 960,\n",
       " 'probability': 961,\n",
       " 'efficiency': 962,\n",
       " 'nli': 963,\n",
       " 'select': 964,\n",
       " 'exploiting': 965,\n",
       " 'inter': 966,\n",
       " 'computer': 967,\n",
       " 'consistency': 968,\n",
       " 'mixed': 969,\n",
       " 'examine': 970,\n",
       " 'hypothesis': 971,\n",
       " 'relational': 972,\n",
       " 'easy': 973,\n",
       " 'introduced': 974,\n",
       " 'public': 975,\n",
       " 'sequential': 976,\n",
       " 'relevance': 977,\n",
       " 'substantial': 978,\n",
       " 'reported': 979,\n",
       " 'distributions': 980,\n",
       " 'tuned': 981,\n",
       " 'following': 982,\n",
       " 'synthetic': 983,\n",
       " 'turn': 984,\n",
       " 'means': 985,\n",
       " 'motivated': 986,\n",
       " 'semantically': 987,\n",
       " 'modal': 988,\n",
       " 'sampling': 989,\n",
       " 'purpose': 990,\n",
       " 'basic': 991,\n",
       " 'native': 992,\n",
       " 'advantage': 993,\n",
       " 'decisions': 994,\n",
       " 'next': 995,\n",
       " 'indicate': 996,\n",
       " 'candidates': 997,\n",
       " 'off': 998,\n",
       " 'position': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-lable word frequency \n",
    "finaldic = {k: v for v,k in enumerate(list(sorteddic.keys())) }\n",
    "finaldic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get author's dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabeling(article):\n",
    "    articlewords = getwordlist(article)\n",
    "    for i in articlewords:\n",
    "        if i in finaldic: \n",
    "            articlewords[articlewords.index(i)] = finaldic[i]\n",
    "        else:\n",
    "            articlewords.remove(i)\n",
    "    return articlewords\n",
    "\n",
    "def authordata(article):\n",
    "    y = article['authorId']\n",
    "    x = relabeling(article)\n",
    "    return x,y\n",
    "\n",
    "def authorvocab(data):\n",
    "    inputsum = []\n",
    "    outputsum  = []\n",
    "    for a in data:\n",
    "        i, o = authordata(a)\n",
    "        inputsum.append(i)\n",
    "        outputsum.append(o)\n",
    "    \n",
    "    return inputsum, outputsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[574,\n",
       "  134,\n",
       "  4966,\n",
       "  3079,\n",
       "  5,\n",
       "  4798,\n",
       "  32,\n",
       "  512,\n",
       "  47,\n",
       "  20,\n",
       "  2336,\n",
       "  12,\n",
       "  4798,\n",
       "  3096,\n",
       "  2634,\n",
       "  235,\n",
       "  1643,\n",
       "  4966,\n",
       "  423,\n",
       "  1,\n",
       "  2076,\n",
       "  2,\n",
       "  3079,\n",
       "  5,\n",
       "  11,\n",
       "  30,\n",
       "  6,\n",
       "  324,\n",
       "  8,\n",
       "  1279,\n",
       "  0,\n",
       "  1846,\n",
       "  1,\n",
       "  4966,\n",
       "  3079,\n",
       "  50,\n",
       "  0,\n",
       "  134,\n",
       "  85,\n",
       "  5,\n",
       "  2336,\n",
       "  12,\n",
       "  4798,\n",
       "  32,\n",
       "  512,\n",
       "  47,\n",
       "  20,\n",
       "  6,\n",
       "  14,\n",
       "  0,\n",
       "  47,\n",
       "  274,\n",
       "  1,\n",
       "  5558,\n",
       "  2186,\n",
       "  19,\n",
       "  4119,\n",
       "  1843,\n",
       "  29,\n",
       "  1618,\n",
       "  2,\n",
       "  6,\n",
       "  405,\n",
       "  0,\n",
       "  1618,\n",
       "  656,\n",
       "  370,\n",
       "  2,\n",
       "  174,\n",
       "  2572,\n",
       "  1164,\n",
       "  6,\n",
       "  197,\n",
       "  9,\n",
       "  0,\n",
       "  84,\n",
       "  82,\n",
       "  19,\n",
       "  2336,\n",
       "  12,\n",
       "  1564,\n",
       "  473,\n",
       "  1317,\n",
       "  4,\n",
       "  31,\n",
       "  82,\n",
       "  19,\n",
       "  115,\n",
       "  2336,\n",
       "  12,\n",
       "  1564,\n",
       "  473,\n",
       "  110,\n",
       "  0,\n",
       "  84,\n",
       "  82,\n",
       "  19,\n",
       "  2336,\n",
       "  12,\n",
       "  4798,\n",
       "  1618,\n",
       "  511,\n",
       "  12,\n",
       "  431,\n",
       "  82,\n",
       "  19,\n",
       "  2336,\n",
       "  12,\n",
       "  1564,\n",
       "  473,\n",
       "  2,\n",
       "  297,\n",
       "  511,\n",
       "  12,\n",
       "  431,\n",
       "  82,\n",
       "  19,\n",
       "  115,\n",
       "  2336,\n",
       "  12,\n",
       "  4798,\n",
       "  49,\n",
       "  750,\n",
       "  698,\n",
       "  9,\n",
       "  2336,\n",
       "  12,\n",
       "  4798,\n",
       "  17,\n",
       "  25926,\n",
       "  55,\n",
       "  112,\n",
       "  2905,\n",
       "  18,\n",
       "  0,\n",
       "  269,\n",
       "  1,\n",
       "  0,\n",
       "  137,\n",
       "  1145,\n",
       "  98,\n",
       "  65,\n",
       "  5,\n",
       "  4966,\n",
       "  47,\n",
       "  1061,\n",
       "  1544,\n",
       "  949,\n",
       "  19,\n",
       "  72,\n",
       "  561,\n",
       "  608,\n",
       "  1,\n",
       "  775],\n",
       " [4063,\n",
       "  2,\n",
       "  6426,\n",
       "  44,\n",
       "  34,\n",
       "  196,\n",
       "  7,\n",
       "  976,\n",
       "  1060,\n",
       "  139,\n",
       "  6,\n",
       "  69,\n",
       "  2,\n",
       "  405,\n",
       "  44,\n",
       "  798,\n",
       "  210,\n",
       "  34,\n",
       "  605,\n",
       "  4,\n",
       "  291,\n",
       "  29,\n",
       "  85,\n",
       "  1060,\n",
       "  139,\n",
       "  8,\n",
       "  28,\n",
       "  3,\n",
       "  1739,\n",
       "  495,\n",
       "  14,\n",
       "  2,\n",
       "  3,\n",
       "  61,\n",
       "  167,\n",
       "  23,\n",
       "  8,\n",
       "  1686,\n",
       "  2497,\n",
       "  1667,\n",
       "  3120,\n",
       "  1,\n",
       "  0,\n",
       "  163,\n",
       "  6,\n",
       "  604,\n",
       "  56,\n",
       "  1875,\n",
       "  1,\n",
       "  48,\n",
       "  20,\n",
       "  2,\n",
       "  0,\n",
       "  680,\n",
       "  9,\n",
       "  163,\n",
       "  3383,\n",
       "  440,\n",
       "  1475,\n",
       "  0,\n",
       "  805,\n",
       "  1,\n",
       "  121,\n",
       "  2,\n",
       "  1352,\n",
       "  4059,\n",
       "  328,\n",
       "  7,\n",
       "  84,\n",
       "  54,\n",
       "  8,\n",
       "  72,\n",
       "  41]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = authorvocab(train_file)\n",
    "x_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'detecting linguistic idiosyncratic interests in autism using distributional semantic models children with autism spectrum disorder often exhibit idiosyncratic patterns of behaviors and interests in this paper we focus on measuring the presence of idiosyncratic interests at the linguistic level in children with autism using distributional semantic models we model the semantic space of children’s narratives by calculating pairwise word overlap and we compare the overlap found within and across diagnostic groups we find that the words used by children with typical development tend to be used by other children with typical development while the words used by children with autism overlap less with those used by children with typical development and even less with those used by other children with autism these findings suggest that children with autism are veering not only away from the topic of the target narrative but also in idiosyncratic semantic directions potentially defined by their individual topics of interest '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reversing(labeled_article):\n",
    "    reversed_finaldic = {v:k for k,v in finaldic.items()}\n",
    "    article = ''\n",
    "    for n in labeled_article:\n",
    "        article += reversed_finaldic[n] + ' '\n",
    "    return article\n",
    "reversing(x_train[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPclassifier for multiclass classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building dataframe for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## re-label the  full dictionary: Choose only the the top xxxxx frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'10' in '0123456678'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "960d5d4d1ec80eea032017859e766fb84cfd43032f2b8cd15e7dce3d9d22c2af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
