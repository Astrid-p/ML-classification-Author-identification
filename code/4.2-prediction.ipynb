{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import getcwd\n",
    "import glob\n",
    "from os.path import join\n",
    "import ntpath\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "import multiprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_path(): \n",
    "   abspath = getcwd()\n",
    "   dname = os.path.dirname(abspath)\n",
    "   os.chdir(dname)\n",
    "\n",
    "set_path()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_NLP(nlpMod, testcase):\n",
    "    modelcount = len(nlpMod.get_feature_names_out()) #all words in train dictionary of one authorb\n",
    "    testcount = nlpMod.transform([testcase]).count_nonzero() \n",
    "    score = testcount / modelcount\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for one case:\n",
    "def prediction(title, abstract):\n",
    "   # preparing test cases: \n",
    "   testcase_NLP = title + \" \" + abstract\n",
    "\n",
    "   # access archive:\n",
    "\n",
    "   pkl_file_list = glob.glob(join(getcwd(),'models_nlp',\"*.pkl\"))\n",
    "   result_records = {}\n",
    "   for fname in pkl_file_list:\n",
    "      _, authid = ntpath.split(fname)\n",
    "      authid = int(authid[:-4])\n",
    "      with open(fname, 'rb') as f:\n",
    "         model = pickle.load(file = f)\n",
    "      \n",
    "      # NLP score\n",
    "      NLP_model = model\n",
    "      score_nlp = score_NLP(NLP_model,testcase_NLP)\n",
    "\n",
    "      result_records[authid] = score_nlp\n",
    "   return max(result_records, key=result_records.get)\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>paperId</th>\n",
       "      <th>title</th>\n",
       "      <th>authorId</th>\n",
       "      <th>authorName</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>venues_le</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1588</td>\n",
       "      <td>45c518aa2dd1538cc56329fbabd58ea9e0b96461</td>\n",
       "      <td>get amr pars</td>\n",
       "      <td>47074942</td>\n",
       "      <td>Chuan Wang</td>\n",
       "      <td>paper propos tackl amr pars bottleneck improv ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2161</td>\n",
       "      <td>1be5a283c7d74ae3657a0b356ef2955d7a3b94eb</td>\n",
       "      <td>empir studi pretrain transform arab inform ext...</td>\n",
       "      <td>37852874</td>\n",
       "      <td>Wuwei Lan</td>\n",
       "      <td>multilingu pretrain transform mbert devlin 201...</td>\n",
       "      <td>2020</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2728</td>\n",
       "      <td>7ac787540a7ffcd79a444dc8824f732873793652</td>\n",
       "      <td>generat refer quantifi express</td>\n",
       "      <td>152371197</td>\n",
       "      <td>James Shaw</td>\n",
       "      <td>paper quantifi generat text generat take advan...</td>\n",
       "      <td>2000</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>40b3bebc595ca091b4ee654e12272ad9201c04dc</td>\n",
       "      <td>transfer learn impact linguist knowledg deep n...</td>\n",
       "      <td>145938140</td>\n",
       "      <td>Nadir Durrani</td>\n",
       "      <td>transfer learn pretrain neural languag model d...</td>\n",
       "      <td>2021</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4784</td>\n",
       "      <td>d50602b6aad3dfa6c098bfea59b8fa5b3eb75edc</td>\n",
       "      <td>look altern center</td>\n",
       "      <td>31380436</td>\n",
       "      <td>M. Strube</td>\n",
       "      <td>propos model determin hearer attent state depe...</td>\n",
       "      <td>1998</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>987</td>\n",
       "      <td>1917c1deb0bf5320ab068cdb8a904859ca804101</td>\n",
       "      <td>kucst sigmorphon 2020 task unsupervis morpholo...</td>\n",
       "      <td>2650725</td>\n",
       "      <td>Manex Agirrezabal</td>\n",
       "      <td>present model unsupervis dis coveri morpholog ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>837</td>\n",
       "      <td>ad1cf7f34d394b5daaee3eea266b7ad44b4f46eb</td>\n",
       "      <td>humor predict dataset humor generat humor head...</td>\n",
       "      <td>47433471</td>\n",
       "      <td>Orion Weller</td>\n",
       "      <td>understand identifi humor increas popular seen...</td>\n",
       "      <td>2020</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>59</td>\n",
       "      <td>bdd4f05c853bb66e8b01b70ac009aa4242c1c4a4</td>\n",
       "      <td>zeroshot text classif reinforc selftrain</td>\n",
       "      <td>2114132405</td>\n",
       "      <td>Zhiquan Ye</td>\n",
       "      <td>zeroshot learn tough problem label data avail ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2099</td>\n",
       "      <td>39283c3d6262b24bd61c88038353f3ed0145b6e4</td>\n",
       "      <td>selfattent crosslingu posit represent</td>\n",
       "      <td>46573238</td>\n",
       "      <td>Liang Ding</td>\n",
       "      <td>posit encod essenti selfattent network san pre...</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1443</td>\n",
       "      <td>8a4257052ead8da5773afeff3aa6b6291ca20f60</td>\n",
       "      <td>build share world map distribut modeltheoret s...</td>\n",
       "      <td>3352951</td>\n",
       "      <td>Aurélie Herbelot</td>\n",
       "      <td>paper introduc approach automat map standard d...</td>\n",
       "      <td>2015</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                   paperId  \\\n",
       "0    1588  45c518aa2dd1538cc56329fbabd58ea9e0b96461   \n",
       "1    2161  1be5a283c7d74ae3657a0b356ef2955d7a3b94eb   \n",
       "2    2728  7ac787540a7ffcd79a444dc8824f732873793652   \n",
       "3      13  40b3bebc595ca091b4ee654e12272ad9201c04dc   \n",
       "4    4784  d50602b6aad3dfa6c098bfea59b8fa5b3eb75edc   \n",
       "..    ...                                       ...   \n",
       "95    987  1917c1deb0bf5320ab068cdb8a904859ca804101   \n",
       "96    837  ad1cf7f34d394b5daaee3eea266b7ad44b4f46eb   \n",
       "97     59  bdd4f05c853bb66e8b01b70ac009aa4242c1c4a4   \n",
       "98   2099  39283c3d6262b24bd61c88038353f3ed0145b6e4   \n",
       "99   1443  8a4257052ead8da5773afeff3aa6b6291ca20f60   \n",
       "\n",
       "                                                title    authorId  \\\n",
       "0                                        get amr pars    47074942   \n",
       "1   empir studi pretrain transform arab inform ext...    37852874   \n",
       "2                      generat refer quantifi express   152371197   \n",
       "3   transfer learn impact linguist knowledg deep n...   145938140   \n",
       "4                                  look altern center    31380436   \n",
       "..                                                ...         ...   \n",
       "95  kucst sigmorphon 2020 task unsupervis morpholo...     2650725   \n",
       "96  humor predict dataset humor generat humor head...    47433471   \n",
       "97           zeroshot text classif reinforc selftrain  2114132405   \n",
       "98              selfattent crosslingu posit represent    46573238   \n",
       "99  build share world map distribut modeltheoret s...     3352951   \n",
       "\n",
       "           authorName                                           abstract  \\\n",
       "0          Chuan Wang  paper propos tackl amr pars bottleneck improv ...   \n",
       "1           Wuwei Lan  multilingu pretrain transform mbert devlin 201...   \n",
       "2          James Shaw  paper quantifi generat text generat take advan...   \n",
       "3       Nadir Durrani  transfer learn pretrain neural languag model d...   \n",
       "4           M. Strube  propos model determin hearer attent state depe...   \n",
       "..                ...                                                ...   \n",
       "95  Manex Agirrezabal  present model unsupervis dis coveri morpholog ...   \n",
       "96       Orion Weller  understand identifi humor increas popular seen...   \n",
       "97         Zhiquan Ye  zeroshot learn tough problem label data avail ...   \n",
       "98         Liang Ding  posit encod essenti selfattent network san pre...   \n",
       "99   Aurélie Herbelot  paper introduc approach automat map standard d...   \n",
       "\n",
       "    year  venues_le  \n",
       "0   2017        102  \n",
       "1   2020        102  \n",
       "2   2000        136  \n",
       "3   2021        119  \n",
       "4   1998         70  \n",
       "..   ...        ...  \n",
       "95  2020        293  \n",
       "96  2020        118  \n",
       "97  2020          5  \n",
       "98  2020          5  \n",
       "99  2015        102  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val= pd.read_pickle('data/processed/val_clean_df.pkl')\n",
    "df_val.reset_index(inplace=True)\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case prediction 0\n",
      "case prediction 1\n",
      "case prediction 2\n",
      "case prediction 3\n",
      "case prediction 4\n",
      "case prediction 5\n",
      "case prediction 6\n",
      "case prediction 7\n",
      "case prediction 8\n",
      "case prediction 9\n",
      "case prediction 10\n",
      "case prediction 11\n",
      "case prediction 12\n",
      "case prediction 13\n",
      "case prediction 14\n",
      "case prediction 15\n",
      "case prediction 16\n",
      "case prediction 17\n",
      "case prediction 18\n",
      "case prediction 19\n",
      "case prediction 20\n",
      "case prediction 21\n",
      "case prediction 22\n",
      "case prediction 23\n",
      "case prediction 24\n",
      "case prediction 25\n",
      "case prediction 26\n",
      "case prediction 27\n",
      "case prediction 28\n",
      "case prediction 29\n",
      "case prediction 30\n",
      "case prediction 31\n",
      "case prediction 32\n",
      "case prediction 33\n",
      "case prediction 34\n",
      "case prediction 35\n",
      "case prediction 36\n",
      "case prediction 37\n",
      "case prediction 38\n",
      "case prediction 39\n",
      "case prediction 40\n",
      "case prediction 41\n",
      "case prediction 42\n",
      "case prediction 43\n",
      "case prediction 44\n",
      "case prediction 45\n",
      "case prediction 46\n",
      "case prediction 47\n",
      "case prediction 48\n",
      "case prediction 49\n",
      "case prediction 50\n",
      "case prediction 51\n",
      "case prediction 52\n",
      "case prediction 53\n",
      "case prediction 54\n",
      "case prediction 55\n",
      "case prediction 56\n",
      "case prediction 57\n",
      "case prediction 58\n",
      "case prediction 59\n",
      "case prediction 60\n",
      "case prediction 61\n",
      "case prediction 62\n",
      "case prediction 63\n",
      "case prediction 64\n",
      "case prediction 65\n",
      "case prediction 66\n",
      "case prediction 67\n",
      "case prediction 68\n",
      "case prediction 69\n",
      "case prediction 70\n",
      "case prediction 71\n",
      "case prediction 72\n",
      "case prediction 73\n",
      "case prediction 74\n",
      "case prediction 75\n",
      "case prediction 76\n",
      "case prediction 77\n",
      "case prediction 78\n",
      "case prediction 79\n",
      "case prediction 80\n",
      "case prediction 81\n",
      "case prediction 82\n",
      "case prediction 83\n",
      "case prediction 84\n",
      "case prediction 85\n",
      "case prediction 86\n",
      "case prediction 87\n",
      "case prediction 88\n",
      "case prediction 89\n",
      "case prediction 90\n",
      "case prediction 91\n",
      "case prediction 92\n",
      "case prediction 93\n",
      "case prediction 94\n",
      "case prediction 95\n",
      "case prediction 96\n",
      "case prediction 97\n",
      "case prediction 98\n",
      "case prediction 99\n"
     ]
    }
   ],
   "source": [
    "# predict all \n",
    "\n",
    "def predict_all(df):\n",
    "   pred = []\n",
    "   for i in range(len(df)):\n",
    "\n",
    "      \n",
    "      print(f'case prediction {i}')\n",
    "      case = df.iloc[i]\n",
    "      title = case[\"title\"]\n",
    "      abstract = case[\"abstract\"]\n",
    "      result = prediction(title, abstract)\n",
    "      pred.append(result)\n",
    "   return pred\n",
    "warnings.filterwarnings('ignore')\n",
    "val_pred = predict_all(df = df_val)\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(df_val['authorId'], val_pred)\n",
    "val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object DataFrame.iterrows at 0x00000230406F6F90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2067579825"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bbd7653c429d3d2de6e8bc2b15128056d2671a20efb53a45ef350876c14518f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
