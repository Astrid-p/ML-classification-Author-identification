{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import getcwd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "import multiprocessing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_path():\n",
    "    abspath = getcwd()\n",
    "    dname = os.path.dirname(abspath)\n",
    "    os.chdir(dname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_place(df, authId, estim = 20):\n",
    "    cats = df[['year', 'venues_le']]\n",
    "    target = df['authorId'] == authId\n",
    "    clf = RandomForestClassifier(n_estimators = estim)\n",
    "    clf = clf.fit(cats, target)\n",
    "\n",
    "    return clf  # prob of pair of cats by author\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>title</th>\n",
       "      <th>authorId</th>\n",
       "      <th>authorName</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>venues_le</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0b341b6938308a6d5f47edf490f6e46eae3835fa</td>\n",
       "      <td>detect linguist idiosyncrat interest autism di...</td>\n",
       "      <td>3188285</td>\n",
       "      <td>Masoud Rouhizadeh</td>\n",
       "      <td>child autism spectrum disord exhibit idiosyncr...</td>\n",
       "      <td>2014</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c682727ee058aadbe9dbf838dcb036322818f588</td>\n",
       "      <td>bigram bilstm neural network sequenti metaphor...</td>\n",
       "      <td>2782720</td>\n",
       "      <td>Yuri Bizzoni</td>\n",
       "      <td>present compar altern deep neural architectur ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0f9b5b32229a7245e43754430c0c88f8e7f0d8af</td>\n",
       "      <td>factual effici integr relev fact visual questi...</td>\n",
       "      <td>144748442</td>\n",
       "      <td>Peter Vickers</td>\n",
       "      <td>visual question answer vqa method aim leverag ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7e8b4cfdc03b59ece2d6b33a217f0abd47f708d9</td>\n",
       "      <td>variat graph autoencod cheap supervis amr core...</td>\n",
       "      <td>46331602</td>\n",
       "      <td>Irene Li</td>\n",
       "      <td>corefer resolut semant graph like amr aim grou...</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07588dd5d0252c7abc99b3834a81bf23741ead4b</td>\n",
       "      <td>limitbert linguist inform multitask bert</td>\n",
       "      <td>30887404</td>\n",
       "      <td>Junru Zhou</td>\n",
       "      <td>paper present linguist inform multitask bert l...</td>\n",
       "      <td>2019</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    paperId  \\\n",
       "0  0b341b6938308a6d5f47edf490f6e46eae3835fa   \n",
       "1  c682727ee058aadbe9dbf838dcb036322818f588   \n",
       "2  0f9b5b32229a7245e43754430c0c88f8e7f0d8af   \n",
       "3  7e8b4cfdc03b59ece2d6b33a217f0abd47f708d9   \n",
       "4  07588dd5d0252c7abc99b3834a81bf23741ead4b   \n",
       "\n",
       "                                               title   authorId  \\\n",
       "0  detect linguist idiosyncrat interest autism di...    3188285   \n",
       "1  bigram bilstm neural network sequenti metaphor...    2782720   \n",
       "2  factual effici integr relev fact visual questi...  144748442   \n",
       "3  variat graph autoencod cheap supervis amr core...   46331602   \n",
       "4           limitbert linguist inform multitask bert   30887404   \n",
       "\n",
       "          authorName                                           abstract  year  \\\n",
       "0  Masoud Rouhizadeh  child autism spectrum disord exhibit idiosyncr...  2014   \n",
       "1       Yuri Bizzoni  present compar altern deep neural architectur ...  2018   \n",
       "2      Peter Vickers  visual question answer vqa method aim leverag ...  2021   \n",
       "3           Irene Li  corefer resolut semant graph like amr aim grou...  2022   \n",
       "4         Junru Zhou  paper present linguist inform multitask bert l...  2019   \n",
       "\n",
       "   venues_le  \n",
       "0         58  \n",
       "1        122  \n",
       "2          5  \n",
       "3          5  \n",
       "4        119  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_path()\n",
    "df_  = pd.read_pickle('data/processed/clean_df.pkl')\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getxy(df):\n",
    "   x = []\n",
    "   y = []\n",
    "   for i in range(len(df)):\n",
    "      tempX = Tfvector.transform(df.iloc[i]['title'] + df.iloc[i]['abstract'])\n",
    "      tempY = df.iloc[i]['authid_enc']\n",
    "      x.append(tempX)\n",
    "      y.append(tempY)\n",
    "   return x, y\n",
    "xtrain, ytrain = getxy(df_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bbd7653c429d3d2de6e8bc2b15128056d2671a20efb53a45ef350876c14518f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
