{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import getcwd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "import os\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from sklearn import  naive_bayes, pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_path():\n",
    "    abspath = getcwd()\n",
    "    dname = os.path.dirname(abspath)\n",
    "    os.chdir(dname)\n",
    "set_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('data/processed/train_clean_df.pkl')\n",
    "df_val = pd.read_pickle('data/processed/val_clean_df.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words:\n",
    "\n",
    "Get x common words out of each author's corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author 198 has maximum unique words: 465\n",
      "author 1407 has maximum unique words: 12\n",
      "average number of unique words per author is 91.06595555555556\n"
     ]
    }
   ],
   "source": [
    "# checking number of unique words in each author's corpus \n",
    "def get_author_unique_corpus(df):\n",
    "   listauthor = df['authId_enc'].unique()\n",
    "   corpus_auth = {}\n",
    "   for au in listauthor:\n",
    "      totalword = []\n",
    "      auth_content = df.loc[df['authId_enc'] == au, 'content']\n",
    "      for art in auth_content:\n",
    "         wordlist = art.split()\n",
    "         totalword += wordlist\n",
    "      corpus_auth[au] = list(set(totalword))\n",
    "   return corpus_auth\n",
    "corpus_by_author = get_author_unique_corpus(df_train)\n",
    "\n",
    "num_corpus = {k:len(v) for k, v in corpus_by_author.items() }\n",
    "max_uniq_w = max(num_corpus, key = num_corpus.get)\n",
    "print(f'author {max_uniq_w} has maximum unique words: {num_corpus[max_uniq_w]}' )\n",
    "min_uniq_w = min(num_corpus, key = num_corpus.get)\n",
    "print(f'author {min_uniq_w} has maximum unique words: {num_corpus[min_uniq_w]}' )\n",
    "print(f'average number of unique words per author is {np.mean(list(num_corpus.values()))}' )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>authId_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>factual effici integr relev fact visual questi...</td>\n",
       "      <td>4134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>limitbert linguist inform multitask bert paper...</td>\n",
       "      <td>2444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataeffici languag shape fewshot imag classif ...</td>\n",
       "      <td>4533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>querydriven topic model topic model unsupervis...</td>\n",
       "      <td>5178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>extract abstract explan factcheck evalu news p...</td>\n",
       "      <td>4884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  authId_enc\n",
       "0  factual effici integr relev fact visual questi...        4134\n",
       "1  limitbert linguist inform multitask bert paper...        2444\n",
       "2  dataeffici languag shape fewshot imag classif ...        4533\n",
       "3  querydriven topic model topic model unsupervis...        5178\n",
       "4  extract abstract explan factcheck evalu news p...        4884"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(max_df=0.5, max_features=3000, norm=None)),\n",
       "                ('classifier', MultinomialNB(alpha=0.5, fit_prior=False))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = df_train['content']\n",
    "ytrain = df_train['authId_enc'].values\n",
    "vectorizer = TfidfVectorizer(max_df=0.5,\n",
    "                              max_features=3000,\n",
    "                              norm=None)\n",
    "classifierNB = naive_bayes.MultinomialNB(fit_prior=False,alpha=0.5)\n",
    "modelNB_3000= pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           (\"classifier\", classifierNB)])\n",
    "\n",
    "modelNB_3000.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17332549941245592"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval = df_val['content'].values\n",
    "yval= df_val['authId_enc'].values\n",
    "predicted = modelNB_3000.predict(Xval)\n",
    "accuracy = accuracy_score(yval, predicted)\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Increasing the size of corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(max_df=0.5, max_features=4000, norm=None)),\n",
       "                ('classifier', MultinomialNB(alpha=0.5, fit_prior=False))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = df_train['content']\n",
    "ytrain = df_train['authId_enc'].values\n",
    "vectorizer = TfidfVectorizer(max_df=0.5,\n",
    "                              max_features=4000,\n",
    "                              norm=None)\n",
    "classifierNB = naive_bayes.MultinomialNB(fit_prior=False,alpha=0.5)\n",
    "modelNB_4000= pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           (\"classifier\", classifierNB)])\n",
    "\n",
    "modelNB_4000.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17508813160987075"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval = df_val['content'].values\n",
    "yval= df_val['authId_enc'].values\n",
    "predicted = modelNB_4000.predict(Xval)\n",
    "accuracy = accuracy_score(yval, predicted)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXTENDING CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(max_df=0.5, max_features=5000, norm=None)),\n",
       "                ('classifier', MultinomialNB(alpha=0.5, fit_prior=False))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = df_train['content']\n",
    "ytrain = df_train['authId_enc'].values\n",
    "vectorizer = TfidfVectorizer(max_df=0.5,\n",
    "                              max_features=5000,\n",
    "                              norm=None)\n",
    "classifierNB = naive_bayes.MultinomialNB(fit_prior=False,alpha=0.5)\n",
    "modelNB_5000= pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           (\"classifier\", classifierNB)])\n",
    "\n",
    "modelNB_5000.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17391304347826086"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval = df_val['content'].values\n",
    "yval= df_val['authId_enc'].values\n",
    "predicted = modelNB_5000.predict(Xval)\n",
    "accuracy = accuracy_score(yval, predicted)\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STACKING DATA FOR REFIT CHOSEN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12119, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = pd.concat([df_train, df_val], ignore_index=True, axis=0)\n",
    "df_combined.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(max_df=0.5, max_features=4000, norm=None)),\n",
       "                ('classifier', MultinomialNB(alpha=0.5, fit_prior=False))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xcombined = df_combined['content'].values\n",
    "ycombined = df_combined['authId_enc'].values\n",
    "modelNB_4000.fit(Xcombined, ycombined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_pickle('data/processed/test_clean_df.pkl')\n",
    "\n",
    "# get lable encoder of author\n",
    "with open('code/authorIdlabel.pkl', 'rb') as f:\n",
    "   authorId_encoder = pickle.load(file = f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6531"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = df_test['content'].values\n",
    "predicted = modelNB_4000.predict(Xtest)\n",
    "predictauthorId = authorId_encoder.inverse_transform(predicted)\n",
    "len(predictauthorId)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>authorId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86e1aaa0c47659e08a896e9889384eb1e5401e6a</td>\n",
       "      <td>1821892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8d3076c38f56df22052567f4783c670d8e860f09</td>\n",
       "      <td>1916865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7c400ee676d427eeda1aad5c1c54c316f0b9773d</td>\n",
       "      <td>1390037280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185e7d2a761594451b02ace240356dadad2aef78</td>\n",
       "      <td>51518773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e4363d077a890c8d5c5e66b82fe69a1bbbdd5c80</td>\n",
       "      <td>49889487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    paperId    authorId\n",
       "0  86e1aaa0c47659e08a896e9889384eb1e5401e6a     1821892\n",
       "1  8d3076c38f56df22052567f4783c670d8e860f09     1916865\n",
       "2  7c400ee676d427eeda1aad5c1c54c316f0b9773d  1390037280\n",
       "3  185e7d2a761594451b02ace240356dadad2aef78    51518773\n",
       "4  e4363d077a890c8d5c5e66b82fe69a1bbbdd5c80    49889487"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictauthorId = list(map(str, predictauthorId))\n",
    "df_test['authorId']= predictauthorId\n",
    "df_test = df_test[['paperId', 'authorId']].copy()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_json('data/processed/predicted_full.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection by chi2\n",
    "Xnames = vectorizer.get_feature_names_out() ## original full corpus\n",
    "p_value_limit = 0.95\n",
    "df_features = pd.DataFrame()\n",
    "for author in np.unique(df_train['authId_enc']):\n",
    "   X= Xtrain.toarray()\n",
    "   Y = df_train['authId_enc'] ==author\n",
    "   chi, p = chi2(X, Y)\n",
    "   df_features = pd.concat([df_features, \n",
    "   pd.DataFrame({'feature': Xnames, 'score' : 1-p, 'authId_enc': author})])\n",
    "\n",
    "   df_features = df_features[df_features['score'] > p_value_limit]\n",
    "df_features = df_features.sort_values(['authId_enc', 'score'],\n",
    "                                          ascending = [True, False])\n",
    "Xnames = df_features['feature'].unique().tolist() # selected words for new corpus from feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 12:\n",
      "  . selected features: 11\n",
      "  . top features: pars,grammar,algorithm,contextfre grammar,contextfre,tabular,pars algorithm,tabular pars,prefix,argument\n",
      " \n",
      "# 241:\n",
      "  . selected features: 12\n",
      "  . top features: vector,crosslingu,vector space,space,word vector,specialis,lexic,monolingu,lexic entail,postprocess\n",
      " \n",
      "# 257:\n",
      "  . selected features: 4\n",
      "  . top features: morpholog,segment,morpholog segment,morpholog tag\n",
      " \n",
      "# 1307:\n",
      "  . selected features: 10\n",
      "  . top features: nli,nativ languag,ensembl,languag identif,nativ,hash,classifi,crosscorpus,identif,metaclassifi\n",
      " \n",
      "# 1776:\n",
      "  . selected features: 7\n",
      "  . top features: lowresourc,encoderdecod,paradigm,characterbas,set,develop set,morpholog reinflect\n",
      " \n",
      "# 2204:\n",
      "  . selected features: 13\n",
      "  . top features: news,user,metaphor,recommend,behavior,news recommend,emoji,multihead,multihead selfattent,selfattent\n",
      " \n",
      "# 2905:\n",
      "  . selected features: 10\n",
      "  . top features: convolut,paraphras,paraphras identif,phrase,minibatch,0shottc,chunk,multigrancnn,convolut neural,deist\n",
      " \n",
      "# 3310:\n",
      "  . selected features: 8\n",
      "  . top features: discours,respons,coher,recurs,adversari,decept,discours pars,life event\n",
      " \n",
      "# 3469:\n",
      "  . selected features: 11\n",
      "  . top features: suicid,stock,financi,ideat,suicid ideat,trade,market,profit,movement,risk\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# PRINT out selected feature by author\n",
    "for author in np.unique(df_train['authId_enc'])[:10]:\n",
    "   print(\"# {}:\".format(author))\n",
    "   print(\"  . selected features:\",\n",
    "         len(df_features[df_features[\"authId_enc\"]==author]))\n",
    "   print(\"  . top features:\", \",\".join(\n",
    "df_features[df_features[\"authId_enc\"]==author][\"feature\"].values[:10]))\n",
    "   print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4985"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit vectorizer in the new corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=Xnames)\n",
    "vectorizer.fit(corpus)\n",
    "Xtrain_new = vectorizer.transform(corpus)\n",
    "ytrain = df_train['authId_enc'].values\n",
    "yval= df_val['authId_enc'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierNB = naive_bayes.MultinomialNB()\n",
    "## pipeline\n",
    "modelNB = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                           (\"classifier\", classifierNB)])\n",
    "## train classifier\n",
    "modelNB[\"classifier\"].fit(Xtrain_new, ytrain)\n",
    "## test\n",
    "Xval = df_val['content'].values\n",
    "predicted = modelNB.predict(Xval)\n",
    "predicted_prob = modelNB.predict_proba(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(yval, predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bbd7653c429d3d2de6e8bc2b15128056d2671a20efb53a45ef350876c14518f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
